
# 动态规划基本解题思路
前置知识

阅读本文前，你需要先学习：

*   [二叉树的遍历框架](https://labuladong.online/algo/data-structure-basic/binary-tree-traverse-basic/)
*   [多叉树结构及遍历框架](https://labuladong.online/algo/data-structure-basic/n-ary-tree-traverse-basic/)

这篇文章是我多年前一篇 200 多赞赏的 [动态规划详解](https://mp.weixin.qq.com/s/1V3aHVonWBEXlNUvK3S28w) 的进阶版，我添加了更多干货内容，希望本文成为解决动态规划的一部「指导方针」。

动态规划问题（Dynamic Programming）应该是很多读者头疼的，不过这类问题也是最具有技巧性，最有意思的。本站使用了整整一个章节专门来写这个算法，动态规划的重要性也可见一斑。

本文解决几个问题：

动态规划是什么？解决动态规划问题有什么技巧？如何学习动态规划？

刷题刷多了就会发现，算法技巧就那几个套路，我们后续的动态规划系列章节，都在使用本文的解题框架思维，如果你心里有数，就会轻松很多。所以本文放在第一章，希望能够成为解决动态规划问题的一部指导方针，下面上干货。

首先，**动态规划问题的一般形式就是求最值**。动态规划其实是运筹学的一种最优化方法，只不过在计算机问题上应用比较多，比如说让你求最长递增子序列呀，最小编辑距离呀等等。

既然是要求最值，核心问题是什么呢？**求解动态规划的核心问题是穷举**。因为要求最值，肯定要把所有可行的答案穷举出来，然后在其中找最值呗。

动态规划这么简单，就是穷举就完事了？我看到的动态规划问题都很难啊！

首先，虽然动态规划的核心思想就是穷举求最值，但是问题可以千变万化，穷举所有可行解其实并不是一件容易的事，需要你熟练掌握递归思维，只有列出**正确的「状态转移方程」**，才能正确地穷举。而且，你需要判断算法问题是否**具备「最优子结构」**，是否能够通过子问题的最值得到原问题的最值。另外，动态规划问题**存在「重叠子问题」**，如果暴力穷举的话效率会很低，所以需要你使用「备忘录」或者「DP table」来优化穷举过程，避免不必要的计算。

以上提到的重叠子问题、最优子结构、状态转移方程就是动态规划三要素。具体什么意思等会会举例详解，但是在实际的算法问题中，写出状态转移方程是最困难的，这也就是为什么很多朋友觉得动态规划问题困难的原因，我来提供我总结的一个思维框架，辅助你思考状态转移方程：

**明确「状态」-> 明确「选择」 -> 定义 `dp` 数组/函数的含义**。

按上面的套路走，最后的解法代码就会是如下的框架：

    # 自顶向下递归的动态规划
    def dp(状态1, 状态2, ...):
        for 选择 in 所有可能的选择:
            # 此时的状态已经因为做了选择而改变
            result = 求最值(result, dp(状态1, 状态2, ...))
        return result
    
    # 自底向上迭代的动态规划
    # 初始化 base case
    dp[0][0][...] = base case
    # 进行状态转移
    for 状态1 in 状态1的所有取值：
        for 状态2 in 状态2的所有取值：
            for ...
                dp[状态1][状态2][...] = 求最值(选择1，选择2...)

下面通过斐波那契数列问题和凑零钱问题来详解动态规划的基本原理。前者主要是让你明白什么是重叠子问题（斐波那契数列没有求最值，所以严格来说不是动态规划问题），后者主要举集中于如何列出状态转移方程。

[一、斐波那契数列](#)
-------------

力扣第 509 题「[斐波那契数](https://leetcode.cn/problems/fibonacci-number/)」就是这个问题，请读者不要嫌弃这个例子简单，**只有简单的例子才能让你把精力充分集中在算法背后的通用思想和技巧上，而不会被那些隐晦的细节问题搞的莫名其妙**。想要困难的例子，接下来的动态规划系列里有的是。

### [暴力递归](#)

斐波那契数列的数学形式就是递归的，写成代码就是这样：


cpp 🤖

    int fib(int N) {
        if (N == 1 || N == 2) return 1;
        return fib(N - 1) + fib(N - 2);
    }



这个不用多说了，学校老师讲递归的时候似乎都是拿这个举例。我们也知道这样写代码虽然简洁易懂，但是十分低效，低效在哪里？假设 n = 20，请画出递归树：

![](https://labuladong.online/algo/images/dynamic-programming/1.jpg)

Tip

但凡遇到需要递归的问题，最好都画出递归树，这对你分析算法的复杂度，寻找算法低效的原因都有巨大帮助。

这个递归树怎么理解？就是说想要计算原问题 `f(20)`，我就得先计算出子问题 `f(19)` 和 `f(18)`，然后要计算 `f(19)`，我就要先算出子问题 `f(18)` 和 `f(17)`，以此类推。最后遇到 `f(1)` 或者 `f(2)` 的时候，结果已知，就能直接返回结果，递归树不再向下生长了。

**递归算法的时间复杂度怎么计算？就是用子问题个数乘以解决一个子问题需要的时间**。

首先计算子问题个数，即递归树中节点的总数。显然二叉树节点总数为指数级别，所以子问题个数为 O(2^n)。

然后计算解决一个子问题的时间，在本算法中，没有循环，只有 `f(n - 1) + f(n - 2)` 一个加法操作，时间为 O(1)。

所以，这个算法的时间复杂度为二者相乘，即 O(2^n)，指数级别，爆炸。

观察递归树，很明显发现了算法低效的原因：存在大量重复计算，比如 `f(18)` 被计算了两次，而且你可以看到，以 `f(18)` 为根的这个递归树体量巨大，多算一遍，会耗费巨大的时间。更何况，还不止 `f(18)` 这一个节点被重复计算，所以这个算法及其低效。

这就是动态规划问题的第一个性质：**重叠子问题**。下面，我们想办法解决这个问题。

### [带备忘录的递归解法](#)

明确了问题，其实就已经把问题解决了一半。即然耗时的原因是重复计算，那么我们可以造一个「备忘录」，每次算出某个子问题的答案后别急着返回，先记到「备忘录」里再返回；每次遇到一个子问题先去「备忘录」里查一查，如果发现之前已经解决过这个问题了，直接把答案拿出来用，不要再耗时去计算了。

一般使用一个数组充当这个「备忘录」，当然你也可以使用哈希表（字典），思想都是一样的。



cpp 🤖

    int fib(int N) {
        // 备忘录全初始化为 0
        vector<int> memo(N + 1, 0);
        // 进行带备忘录的递归
        return dp(memo, N);
    }
    
    // 带着备忘录进行递归
    int dp(vector<int>& memo, int n) {
        // base case
        if (n == 0 || n == 1) return n;
        // 已经计算过，不用再计算了
        if (memo[n] != 0) return memo[n];
        memo[n] = dp(memo, n - 1) + dp(memo, n - 2);
        return memo[n];
    }


现在，画出递归树，你就知道「备忘录」到底做了什么。

![](https://labuladong.online/algo/images/dynamic-programming/2.jpg)

实际上，带「备忘录」的递归算法，把一棵存在巨量冗余的递归树通过「剪枝」，改造成了一幅不存在冗余的递归图，极大减少了子问题（即递归图中节点）的个数。

![](https://labuladong.online/algo/images/dynamic-programming/3.jpg)

**递归算法的时间复杂度怎么计算？就是用子问题个数乘以解决一个子问题需要的时间**。

子问题个数，即图中节点的总数，由于本算法不存在冗余计算，子问题就是 `f(1)`, `f(2)`, `f(3)` ... `f(20)`，数量和输入规模 n = 20 成正比，所以子问题个数为 O(n)。

解决一个子问题的时间，同上，没有什么循环，时间为 O(1)。

所以，本算法的时间复杂度是 O(n)，比起暴力算法，是降维打击。

至此，带备忘录的递归解法的效率已经和迭代的动态规划解法一样了。实际上，这种解法和常见的动态规划解法已经差不多了，只不过这种解法是「自顶向下」进行「递归」求解，我们更常见的动态规划代码是「自底向上」进行「递推」求解。

啥叫「自顶向下」？注意我们刚才画的递归树（或者说图），是从上向下延伸，都是从一个规模较大的原问题比如说 `f(20)`，向下逐渐分解规模，直到 `f(1)` 和 `f(2)` 这两个 base case，然后逐层返回答案，这就叫「自顶向下」。

啥叫「自底向上」？反过来，我们直接从最底下、最简单、问题规模最小、已知结果的 `f(1)` 和 `f(2)`（base case）开始往上推，直到推到我们想要的答案 `f(20)`。这就是「递推」的思路，这也是动态规划一般都脱离了递归，而是由循环迭代完成计算的原因。

### [`dp` 数组的迭代（递推）解法](#)

有了上一步「备忘录」的启发，我们可以把这个「备忘录」独立出来成为一张表，通常叫做 DP table，在这张表上完成「自底向上」的推算岂不美哉！


cpp 🤖

    int fib(int N) {
        if (N == 0) return 0;
        vector<int> dp(N + 1);
        // base case
        dp[0] = 0; dp[1] = 1;
        // 状态转移
        for (int i = 2; i <= N; i++) {
            dp[i] = dp[i - 1] + dp[i - 2];
        }
    
        return dp[N];
    }


画个图就很好理解了，而且你发现这个 DP table 特别像之前那个「剪枝」后的结果，只是反过来算而已：

![](https://labuladong.online/algo/images/dynamic-programming/4.jpg)

实际上，带备忘录的递归解法中的那个「备忘录」`memo` 数组，最终完成后就是这个解法中的 `dp` 数组，你对比一下可视化面板中两个算法执行的过程可以更直观地看出它俩的联系。

所以说自顶向下、自底向上两种解法本质其实是差不多的，大部分情况下，效率也基本相同。

### [拓展延伸](#)

这里，引出「状态转移方程」这个名词，实际上就是描述问题结构的数学形式：

![](https://labuladong.online/algo/images/dynamic-programming/fib.png)

为啥叫「状态转移方程」？其实就是为了听起来高端。

`f(n)` 的函数参数会不断变化，所以你把参数 `n` 想做一个状态，这个状态 `n` 是由状态 `n - 1` 和状态 `n - 2` 转移（相加）而来，这就叫状态转移，仅此而已。

你会发现，上面的几种解法中的所有操作，例如 `return f(n - 1) + f(n - 2)`，`dp[i] = dp[i - 1] + dp[i - 2]`，以及对备忘录或 DP table 的初始化操作，都是围绕这个方程式的不同表现形式。

可见列出「状态转移方程」的重要性，它是解决问题的核心，而且很容易发现，其实状态转移方程直接代表着暴力解法。

**千万不要看不起暴力解，动态规划问题最困难的就是写出这个暴力解，即状态转移方程**。

只要写出暴力解，优化方法无非是用备忘录或者 DP table，再无奥妙可言。

这个例子的最后，讲一个细节优化。

细心的读者会发现，根据斐波那契数列的状态转移方程，当前状态 `n` 只和之前的 `n-1, n-2` 两个状态有关，其实并不需要那么长的一个 DP table 来存储所有的状态，只要想办法存储之前的两个状态就行了。

所以，可以进一步优化，把空间复杂度降为 O(1)。这也就是我们最常见的计算斐波那契数的算法：


cpp 🤖

    int fib(int n) {
        if (n == 0 || n == 1) {
            // base case
            return n;
        }
        // 分别代表 dp[i - 1] 和 dp[i - 2]
        int dp_i_1 = 1, dp_i_2 = 0;
        for (int i = 2; i <= n; i++) {
            // dp[i] = dp[i - 1] + dp[i - 2];
            int dp_i = dp_i_1 + dp_i_2;
            // 滚动更新
            dp_i_2 = dp_i_1;
            dp_i_1 = dp_i;
        }
        return dp_i_1;
    }


这一般是动态规划问题的最后一步优化，如果我们发现每次状态转移只需要 DP table 中的一部分，那么可以尝试缩小 DP table 的大小，只记录必要的数据，从而降低空间复杂度。

上述例子就相当于把 DP table 的大小从 `n` 缩小到 2，即把空间复杂度下降了一个量级。我会在后文 [对动态规划发动降维打击](https://labuladong.online/algo/dynamic-programming/space-optimization/) 进一步讲解这个压缩空间复杂度的技巧，一般来说用来把一个二维的 DP table 压缩成一维，即把空间复杂度从 O(n^2) 压缩到 O(n)。

有人会问，动态规划的另一个重要特性「最优子结构」，怎么没有涉及？下面会涉及。斐波那契数列的例子严格来说不算动态规划，因为没有涉及求最值，以上旨在说明重叠子问题的消除方法，演示得到最优解法逐步求精的过程。下面，看第二个例子，凑零钱问题。

[二、凑零钱问题](#)
------------

这是力扣第 322 题「[零钱兑换](https://leetcode.cn/problems/coin-change/)」：

给你 `k` 种面值的硬币，面值分别为 `c1, c2 ... ck`，每种硬币的数量无限，再给一个总金额 `amount`，问你**最少**需要几枚硬币凑出这个金额，如果不可能凑出，算法返回 -1 。算法的函数签名如下：


cpp 🤖

    // coins 中是可选硬币面值，amount 是目标金额
    int coinChange(vector<int>& coins, int amount);


比如说 `k = 3`，面值分别为 1，2，5，总金额 `amount = 11`。那么最少需要 3 枚硬币凑出，即 11 = 5 + 5 + 1。

你认为计算机应该如何解决这个问题？显然，就是把所有可能的凑硬币方法都穷举出来，然后找找看最少需要多少枚硬币。

### [暴力递归](#)

首先，这个问题是动态规划问题，因为它具有「最优子结构」的。**要符合「最优子结构」，子问题间必须互相独立**。啥叫相互独立？你肯定不想看数学证明，我用一个直观的例子来讲解。

比如说，假设你考试，每门科目的成绩都是互相独立的。你的原问题是考出最高的总成绩，那么你的子问题就是要把语文考到最高，数学考到最高…… 为了每门课考到最高，你要把每门课相应的选择题分数拿到最高，填空题分数拿到最高…… 当然，最终就是你每门课都是满分，这就是最高的总成绩。

得到了正确的结果：最高的总成绩就是总分。因为这个过程符合最优子结构，「每门科目考到最高」这些子问题是互相独立，互不干扰的。

但是，如果加一个条件：你的语文成绩和数学成绩会互相制约，不能同时达到满分，数学分数高，语文分数就会降低，反之亦然。

这样的话，显然你能考到的最高总成绩就达不到总分了，按刚才那个思路就会得到错误的结果。因为「每门科目考到最高」的子问题并不独立，语文数学成绩户互相影响，无法同时最优，所以最优子结构被破坏。

回到凑零钱问题，为什么说它符合最优子结构呢？假设你有面值为 `1, 2, 5` 的硬币，你想求 `amount = 11` 时的最少硬币数（原问题），如果你知道凑出 `amount = 10, 9, 6` 的最少硬币数（子问题），你只需要把子问题的答案加一（再选一枚面值为 `1, 2, 5` 的硬币），求个最小值，就是原问题的答案。因为硬币的数量是没有限制的，所以子问题之间没有相互制，是互相独立的。

Tip

关于最优子结构的问题，后文 [动态规划答疑篇](https://labuladong.online/algo/dynamic-programming/faq-summary/) 还会再举例探讨。

那么，既然知道了这是个动态规划问题，就要思考如何列出正确的状态转移方程？

**1、确定「状态」，也就是原问题和子问题中会变化的变量**。由于硬币数量无限，硬币的面额也是题目给定的，只有目标金额会不断地向 base case 靠近，所以唯一的「状态」就是目标金额 `amount`。

**2、确定「选择」，也就是导致「状态」产生变化的行为**。目标金额为什么变化呢，因为你在选择硬币，你每选择一枚硬币，就相当于减少了目标金额。所以说所有硬币的面值，就是你的「选择」。

**3、明确 `dp` 函数/数组的定义**。我们这里讲的是自顶向下的解法，所以会有一个递归的 `dp` 函数，一般来说函数的参数就是状态转移中会变化的量，也就是上面说到的「状态」；函数的返回值就是题目要求我们计算的量。就本题来说，状态只有一个，即「目标金额」，题目要求我们计算凑出目标金额所需的最少硬币数量。

**所以我们可以这样定义 `dp` 函数：`dp(n)` 表示，输入一个目标金额 `n`，返回凑出目标金额 `n` 所需的最少硬币数量**。

那么根据这个定义，我们的最终答案就是 `dp(amount)` 的返回值。

搞清楚上面这几个关键点，解法的伪码就可以写出来了：


cpp 🤖

    // 伪码框架
    int coinChange(vector<int>& coins, int amount) {
        // 题目要求的最终结果是 dp(amount)
        return dp(coins, amount);
    }
    
    // 定义：要凑出金额 n，至少要 dp(coins, n) 个硬币
    int dp(vector<int>& coins, int n) {
        // 做选择，选择需要硬币最少的那个结果
        int res = INT_MAX;
        for (const int coin : coins) {
            res = min(res, subProb + 1);
        }
        return res;
    }


根据伪码，我们加上 base case 即可得到最终的答案。显然目标金额为 0 时，所需硬币数量为 0；当目标金额小于 0 时，无解，返回 -1：

cpp 🤖

    class Solution {
    public:
        int coinChange(vector<int>& coins, int amount) {
            // 题目要求的最终结果是 dp(amount)
            return dp(coins, amount);
        }
    
    private:
        // 定义：要凑出金额 n，至少要 dp(coins, n) 个硬币
        int dp(vector<int>& coins, int amount) {
            // base case
            if (amount == 0) return 0;
            if (amount < 0) return -1;
    
            int res = INT_MAX;
            for (int coin : coins) {
                // 计算子问题的结果
                int subProblem = dp(coins, amount - coin);
                // 子问题无解则跳过
                if (subProblem == -1) continue;
                // 在子问题中选择最优解，然后加一
                res = min(res, subProblem + 1);
            }
    
            return res == INT_MAX ? -1 : res;
        }
    };


Info

这里 `coinChange` 和 `dp` 函数的签名完全一样，所以理论上不需要额外写一个 `dp` 函数。但为了后文讲解方便，这里还是另写一个 `dp` 函数来实现主要逻辑。

另外，我经常看到有读者留言问，子问题的结果为什么要加 1（`subProblem + 1`），而不是加硬币金额之类的。我这里统一提示一下，动态规划问题的关键是 `dp` 函数/数组的定义，你这个函数的返回值代表什么？你回过头去搞清楚这一点，然后就知道为什么要给子问题的返回值加 1 了。

[Algorithm visualize](https://labuladong.online/algo-visualize/tutorial/coin-change-brute-force/)   **算法可视化面板**Link copied!

至此，状态转移方程其实已经完成了，以上算法已经是暴力解法了，以上代码的数学形式就是状态转移方程：

![](https://labuladong.online/algo/images/dynamic-programming/coin.png)

至此，这个问题其实就解决了，只不过需要消除一下重叠子问题，比如 `amount = 11, coins = {1,2,5}` 时画出递归树看看：

![](https://labuladong.online/algo/images/dynamic-programming/5.jpg)

**递归算法的时间复杂度分析：子问题总数 x 解决每个子问题所需的时间**。

子问题总数为递归树的节点个数，但算法会进行剪枝，剪枝的时机和题目给定的具体硬币面额有关，所以可以想象，这棵树生长的并不规则，确切算出树上有多少节点是比较困难的。对于这种情况，我们一般的做法是按照最坏的情况估算一个时间复杂度的上界。

假设目标金额为 `n`，给定的硬币个数为 `k`，那么递归树最坏情况下高度为 `n`（全用面额为 1 的硬币），然后再假设这是一棵满 `k` 叉树，则节点的总数在 `k^n` 这个数量级。

接下来看每个子问题的复杂度，由于每次递归包含一个 for 循环，复杂度为 O(k)O(k)O(k)，相乘得到总时间复杂度为 O(kn)O(k^n)O(kn)，指数级别。

### [带备忘录的递归](#)

类似之前斐波那契数列的例子，只需要稍加修改，就可以通过备忘录消除子问题：


cpp 🤖

    class Solution {
    public:
        vector<int> memo;
        
        int coinChange(vector<int>& coins, int amount) {
            memo = vector<int> (amount + 1, -666);
            // 备忘录初始化为一个不会被取到的特殊值，代表还未被计算
            return dp(coins, amount);
        }
    
        int dp(vector<int>& coins, int amount) {
            if (amount == 0) return 0;
            if (amount < 0) return -1;
            // 查备忘录，防止重复计算
            if (memo[amount] != -666)
                return memo[amount];
    
            int res = INT_MAX;
            for (int coin : coins) {
                // 计算子问题的结果
                int subProblem = dp(coins, amount - coin);
                // 子问题无解则跳过
                if (subProblem == -1) continue;
                // 在子问题中选择最优解，然后加一
                res = min(res, subProblem + 1);
            }
            // 把计算结果存入备忘录
            memo[amount] = (res == INT_MAX) ? -1 : res;
            return memo[amount];
        }
    };


不画图了，很显然「备忘录」大大减小了子问题数目，完全消除了子问题的冗余，所以子问题总数不会超过金额数 `n`，即子问题数目为 O(n)O(n)O(n)。处理一个子问题的时间不变，仍是 O(k)O(k)O(k)，所以总的时间复杂度是 O(kn)O(kn)O(kn)。

### [dp 数组的迭代解法](#)

当然，我们也可以自底向上使用 dp table 来消除重叠子问题，关于「状态」「选择」和 base case 与之前没有区别，`dp` 数组的定义和刚才 `dp` 函数类似，也是把「状态」，也就是目标金额作为变量。不过 `dp` 函数体现在函数参数，而 `dp` 数组体现在数组索引：

**`dp` 数组的定义：当目标金额为 `i` 时，至少需要 `dp[i]` 枚硬币凑出**。

根据我们文章开头给出的动态规划代码框架可以写出如下解法：

cpp 🤖

    class Solution {
    public:
        int coinChange(vector<int>& coins, int amount) {
            // 数组大小为 amount + 1，初始值也为 amount + 1
            vector<int> dp(amount + 1, amount + 1);
    
            dp[0] = 0;
            // base case
            // 外层 for 循环在遍历所有状态的所有取值
            for (int i = 0; i < dp.size(); i++) {
                // 内层 for 循环在求所有选择的最小值
                for (int coin : coins) {
                    // 子问题无解，跳过
                    if (i - coin < 0) {
                        continue;
                    }
                    dp[i] = min(dp[i], 1 + dp[i - coin]);
                }
            }
            return (dp[amount] == amount + 1) ? -1 : dp[amount];
        }
    };


Info

为啥 `dp` 数组中的值都初始化为 `amount + 1` 呢，因为凑成 `amount` 金额的硬币数最多只可能等于 `amount`（全用 1 元面值的硬币），所以初始化为 `amount + 1` 就相当于初始化为正无穷，便于后续取最小值。为啥不直接初始化为 int 型的最大值 `Integer.MAX_VALUE` 呢？因为后面有 `dp[i - coin] + 1`，这就会导致整型溢出。

![](https://labuladong.online/algo/images/dynamic-programming/6.jpg)

[三、最后总结](#)
-----------

第一个斐波那契数列的问题，解释了如何通过「备忘录」或者「dp table」的方法来优化递归树，并且明确了这两种方法本质上是一样的，只是自顶向下和自底向上的不同而已。

第二个凑零钱的问题，展示了如何流程化确定「状态转移方程」，只要通过状态转移方程写出暴力递归解，剩下的也就是优化递归树，消除重叠子问题而已。

如果你不太了解动态规划，还能看到这里，真得给你鼓掌，相信你已经掌握了这个算法的设计技巧。

**计算机解决问题其实没有任何特殊的技巧，它唯一的解决办法就是穷举**，穷举所有可能性。算法设计无非就是先思考「如何穷举」，然后再追求「如何聪明地穷举」。

列出状态转移方程，就是在解决「如何穷举」的问题。之所以说它难，一是因为很多穷举需要递归实现，二是因为有的问题本身的解空间复杂，不那么容易穷举完整。

备忘录、DP table 就是在追求「如何聪明地穷举」。用空间换时间的思路，是降低时间复杂度的不二法门，除此之外，试问，还能玩出啥花活？

之后我们会有一章专门讲解动态规划问题，如果有任何问题都可以随时回来重读本文，希望读者在阅读每个题目和解法时，多往「状态」和「选择」上靠，才能对这套框架产生自己的理解，运用自如。

* * *

**引用本文的题目**

| 题目编号 | 题目名称 | 中文网站链接 | 题目描述 |
| --- | --- | --- | --- |
| 111 | 二叉树的最小深度 | [力扣（LeetCode）](https://leetcode.cn/problems/minimum-depth-of-binary-tree/?show=1) | 二叉树的最小深度 |
| 112 | 路径总和 | [力扣（LeetCode）](https://leetcode.cn/problems/path-sum/?show=1) | 路径总和 |
| 115 | 不同的子序列 | [力扣（LeetCode）](https://leetcode.cn/problems/distinct-subsequences/?show=1) | 不同的子序列 |
| 139 | 单词拆分 | [力扣（LeetCode）](https://leetcode.cn/problems/word-break/?show=1) | 单词拆分 |
| 1696 | 跳跃游戏 VI | [力扣（LeetCode）](https://leetcode.cn/problems/jump-game-vi/?show=1) | 跳跃游戏 VI |
| 221 | 最大正方形 | [力扣（LeetCode）](https://leetcode.cn/problems/maximal-square/?show=1) | 最大正方形 |
| 240 | 搜索二维矩阵 II | [力扣（LeetCode）](https://leetcode.cn/problems/search-a-2d-matrix-ii/?show=1) | 搜索二维矩阵 II |
| 256 | 粉刷房子 | [力扣（LeetCode）](https://leetcode.cn/problems/paint-house/?show=1) | 粉刷房子 |
| 279 | 完全平方数 | [力扣（LeetCode）](https://leetcode.cn/problems/perfect-squares/?show=1) | 完全平方数 |
| 343 | 整数拆分 | [力扣（LeetCode）](https://leetcode.cn/problems/integer-break/?show=1) | 整数拆分 |
| 365 | 水壶问题 | [力扣（LeetCode）](https://leetcode.cn/problems/water-and-jug-problem/?show=1) | 水壶问题 |
| 542 | 01 矩阵 | [力扣（LeetCode）](https://leetcode.cn/problems/01-matrix/?show=1) | 01 矩阵 |
| 576 | 出界的路径数 | [力扣（LeetCode）](https://leetcode.cn/problems/out-of-boundary-paths/?show=1) | 出界的路径数 |
| 62 | 不同路径 | [力扣（LeetCode）](https://leetcode.cn/problems/unique-paths/?show=1) | 不同路径 |
| 63 | 不同路径 II | [力扣（LeetCode）](https://leetcode.cn/problems/unique-paths-ii/?show=1) | 不同路径 II |
| 70 | 爬楼梯 | [力扣（LeetCode）](https://leetcode.cn/problems/climbing-stairs/?show=1) | 爬楼梯 |
| 91 | 解码方法 | [力扣（LeetCode）](https://leetcode.cn/problems/decode-ways/?show=1) | 解码方法 |
| 剑指 Offer 04 | 二维数组中的查找 | [力扣（LeetCode）](https://leetcode.cn/problems/er-wei-shu-zu-zhong-de-cha-zhao-lcof/?show=1) | 二维数组中的查找 |
| 剑指 Offer 10- I | 斐波那契数列 | [力扣（LeetCode）](https://leetcode.cn/problems/fei-bo-na-qi-shu-lie-lcof/?show=1) | 斐波那契数列 |
| 剑指 Offer 10- II | 青蛙跳台阶问题 | [力扣（LeetCode）](https://leetcode.cn/problems/qing-wa-tiao-tai-jie-wen-ti-lcof/?show=1) | 青蛙跳台阶问题 |
| 剑指 Offer 14- I | 剪绳子 | [力扣（LeetCode）](https://leetcode.cn/problems/jian-sheng-zi-lcof/?show=1) | 剪绳子 |
| 剑指 Offer 46 | 把数字翻译成字符串 | [力扣（LeetCode）](https://leetcode.cn/problems/ba-shu-zi-fan-yi-cheng-zi-fu-chuan-lcof/?show=1) | 把数字翻译成字符串 |
| 剑指 Offer II 091 | 粉刷房子 | [力扣（LeetCode）](https://leetcode.cn/problems/JEj789/?show=1) | 粉刷房子 |
| 剑指 Offer II 097 | 子序列的数目 | [力扣（LeetCode）](https://leetcode.cn/problems/21dk04/?show=1) | 子序列的数目 |
| 剑指 Offer II 098 | 路径的数目 | [力扣（LeetCode）](https://leetcode.cn/problems/2AoeFn/?show=1) | 路径的数目 |
| 剑指 Offer II 103 | 最少的硬币数目 | [力扣（LeetCode）](https://leetcode.cn/problems/gaM7Ch/?show=1) | 最少的硬币数目 |







# 动态规划技巧



很多读者对动态规划问题的 base case、备忘录初始值等问题存在疑问，本文就专门讲一讲这类问题，顺便聊一聊怎么通过题目的蛛丝马迹揣测出题人的小心思，辅助我们解题。

看下力扣第 931 题「[下降路径最小和](https://leetcode.cn/problems/minimum-falling-path-sum/)」，输入为一个 `n * n` 的二维数组 `matrix`，请你计算从第一行落到最后一行，经过的路径和最小为多少：

**931\. 下降路径最小和** | [力扣](https://leetcode.cn/problems/minimum-falling-path-sum/) | [LeetCode](https://leetcode.com/problems/minimum-falling-path-sum/) |  🟠

给你一个 `n x n` 的 **方形** 整数数组 `matrix` ，请你找出并返回通过 `matrix` 的**下降路径** 的 **最小和** 。

**下降路径** 可以从第一行中的任何元素开始，并从每一行中选择一个元素。在下一行选择的元素和当前行所选元素最多相隔一列（即位于正下方或者沿对角线向左或者向右的第一个元素）。具体来说，位置 `(row, col)` 的下一个元素应当是 `(row + 1, col - 1)`、`(row + 1, col)` 或者 `(row + 1, col + 1)` 。

**示例 1：**

![](https://labuladong.online/algo/images/lc/uploads/2021/11/03/failing1-grid.jpg)

**输入：**matrix = \[\[2,1,3\],\[6,5,4\],\[7,8,9\]\]
**输出：**13
**解释：**如图所示，为和最小的两条下降路径

**示例 2：**

![](https://labuladong.online/algo/images/lc/uploads/2021/11/03/failing2-grid.jpg)

**输入：**matrix = \[\[-19,57\],\[-40,-5\]\]
**输出：**\-59
**解释：**如图所示，为和最小的下降路径

**提示：**

*   `n == matrix.length == matrix[i].length`
*   `1 <= n <= 100`
*   `-100 <= matrix[i][j] <= 100`

**题目来源：[力扣 931. 下降路径最小和](https://leetcode.cn/problems/minimum-falling-path-sum/)。**

函数签名如下：


cpp 🤖

    int minFallingPathSum(vector<vector<int>>& matrix);


今天这道题不算是困难的题目，所以**我借这道题来讲讲 base case 的返回值、备忘录的初始值、索引越界情况的返回值如何确定**。

不过还是要根据 [动态规划的标准套路](https://labuladong.online/algo/essential-technique/dynamic-programming-framework/) 讲一下这道题的解题思路。


首先，我们可以定义一个 `dp` 数组：



cpp 🤖

    int dp(vector<vector<int>>& matrix, int i, int j);

这个 `dp` 函数的含义如下：

**从第一行（`matrix[0][..]`）向下落，落到位置 `matrix[i][j]` 的最小路径和为 `dp(matrix, i, j)`**。

根据这个定义，我们可以把主函数的逻辑写出来：


cpp 🤖

    int minFallingPathSum(vector<vector<int>>& matrix) {
        int n = matrix.size();
        int res = INT_MAX;
    
        // 终点可能在最后一行的任意一列
        for (int j = 0; j < n; j++) {
            res = min(res, dp(matrix, n - 1, j));
        }
    
        return res;
    }


因为我们可能落到最后一行的任意一列，所以要穷举一下，看看落到哪一列才能得到最小的路径和。

接下来看看 `dp` 函数如何实现。

对于 `matrix[i][j]`，只有可能从 `matrix[i-1][j], matrix[i-1][j-1], matrix[i-1][j+1]` 这三个位置转移过来。

![](https://labuladong.online/algo/images/memo-basic/1.jpeg)

**那么，只要知道到达 `(i-1, j), (i-1, j-1), (i-1, j+1)` 这三个位置的最小路径和，加上 `matrix[i][j]` 的值，就能够计算出来到达位置 `(i, j)` 的最小路径和**：


cpp 🤖

    int dp(vector<vector<int>>& matrix, int i, int j) {
        // 非法索引检查
        if (i < 0 || j < 0 ||
            i >= matrix.size() ||
            j >= matrix[0].size()) {
            // 返回一个特殊值
            return 99999;
        }
        // base case
        if (i == 0) {
            return matrix[i][j];
        }
        // 状态转移
        return matrix[i][j] + min({
                dp(matrix, i - 1, j), 
                dp(matrix, i - 1, j - 1),
                dp(matrix, i - 1, j + 1)
            });
    }


当然，上述代码是暴力穷举解法，我们可以用备忘录的方法消除重叠子问题，完整代码如下：

cpp 🤖

    #include <vector>
    #include <climits>
    #include <algorithm>
    
    using namespace std;
    
    class Solution {
    public:
        int minFallingPathSum(vector<vector<int>>& matrix) {
            int n = matrix.size();
            int res = INT_MAX;
            // 备忘录里的值初始化为 66666
            memo = vector<vector<int>>(n, vector<int>(n, 66666));
            for (int j = 0; j < n; j++) {
                // 终点可能在 matrix[n-1] 的任意一列
                res = min(res, dp(matrix, n - 1, j));
            }
            return res;
        }
    
        // 备忘录
        vector<vector<int>> memo;
    
        int dp(vector<vector<int>>& matrix, int i, int j) {
            // 1、索引合法性检查
            if (i < 0 || j < 0 ||
                i >= matrix.size() ||
                j >= matrix[0].size()) {
    
                return INT_MAX;
            }
            // 2、base case
            if (i == 0) {
                return matrix[0][j];
            }
            // 3、查找备忘录，防止重复计算
            if (memo[i][j] != 66666) {
                return memo[i][j];
            }
            // 进行状态转移
            memo[i][j] = matrix[i][j] + myMin(
                dp(matrix, i - 1, j),
                dp(matrix, i - 1, j - 1),
                dp(matrix, i - 1, j + 1)
            );
    
            return memo[i][j];
        }
    
        // Helper function to find the minimum of three integers
        int myMin(int a, int b, int c) {
            return min(a, min(b, c));
        }
    };


如果你看过其他的动态规划系列文章，这个解题思路应该是非常容易理解的。

**那么本文对于这个 `dp` 函数仔细探讨三个问题**：

1、对于索引的合法性检测，返回值为什么是 99999？其他的值行不行？

2、base case 为什么是 `i == 0`？

3、备忘录 `memo` 的初始值为什么是 66666？其他值行不行？

[base case 的条件如何确定？](#)
-----------------------

**首先，说说 base case 为什么是 `i == 0`，返回值为什么是 `matrix[0][j]`，这是根据 `dp` 函数的定义所决定的**。

回顾我们的 `dp` 函数定义：

从第一行（`matrix[0][..]`）向下落，落到位置 `matrix[i][j]` 的最小路径和为 `dp(matrix, i, j)`。

根据这个定义，我们就是从 `matrix[0][j]` 开始下落。那如果我们想落到的目的地就是 `i == 0`，所需的路径和当然就是 `matrix[0][j]` 呗。

[备忘录的初始值如何确定？](#)
-----------------

**再说说备忘录 `memo` 的初始值为什么是 66666，这是由题目给出的数据范围决定的**。

备忘录 `memo` 数组的作用是什么？

就是防止重复计算，将 `dp(matrix, i, j)` 的计算结果存进 `memo[i][j]`，遇到重复计算可以直接返回。

那么，我们必须要知道 `memo[i][j]` 到底存储计算结果没有，对吧？如果存结果了，就直接返回；没存，就去递归计算。

所以，`memo` 的初始值一定得是特殊值，和合法的答案有所区分。

我们回过头看看题目给出的数据范围：

> `matrix` 是 `n x n` 的二维数组，其中 `1 <= n <= 100`；对于二维数组中的元素，有 `-100 <= matrix[i][j] <= 100`。

假设 `matrix` 的大小是 100 x 100，所有元素都是 100，那么从第一行往下落，得到的路径和就是 100 x 100 = 10000，也就是最大的合法答案。

类似的，依然假设 `matrix` 的大小是 100 x 100，所有元素是 -100，那么从第一行往下落，就得到了最小的合法答案 -100 x 100 = -10000。

也就是说，这个问题的合法结果会落在区间 `[-10000, 10000]` 中。

所以，我们 `memo` 的初始值就要避开区间 `[-10000, 10000]`，换句话说，`memo` 的初始值只要在区间 `(-inf, -10001] U [10001, +inf)` 中就可以。

[边界情况的返回值如何确定？](#)
------------------

**最后，说说对于不合法的索引，返回值应该如何确定，这需要根据我们状态转移方程的逻辑确定**。

对于这道题，状态转移的基本逻辑如下：

    int dp(int[][] matrix, int i, int j) {
    
        return matrix[i][j] + min(
                dp(matrix, i - 1, j), 
                dp(matrix, i - 1, j - 1),
                dp(matrix, i - 1, j + 1)
            );
    }

显然，`i - 1, j - 1, j + 1` 这几个运算可能会造成索引越界，对于索引越界的 `dp` 函数，应该返回一个不可能被取到的值。

因为我们调用的是 `min` 函数，最终返回的值是最小值，所以对于不合法的索引，只要 `dp` 函数返回一个永远不会被取到的最大值即可。

刚才说了，合法答案的区间是 `[-10000, 10000]`，所以我们的返回值只要大于 10000 就相当于一个永不会取到的最大值。

换句话说，只要返回区间 `[10001, +inf)` 中的一个值，就能保证不会被取到。

至此，我们就把动态规划相关的三个细节问题举例说明了。

**拓展延伸一下，建议大家做题时，除了题意本身，一定不要忽视题目给定的其他信息**。

本文举的例子，测试用例数据范围可以确定「什么是特殊值」，从而帮助我们将思路转化成代码。

除此之外，数据范围还可以帮我们估算算法的时间/空间复杂度。

比如说，有的算法题，你只想到一个暴力求解思路，时间复杂度比较高。如果发现题目给定的数据量比较大，那么肯定可以说明这个求解思路有问题或者存在优化的空间。

除了数据范围，有时候题目还会限制我们算法的时间复杂度，这种信息其实也暗示着一些东西。

比如要求我们的算法复杂度是 O(NlogN)O(NlogN)O(NlogN)，你想想怎么才能搞出一个对数级别的复杂度呢？

肯定得用到 [二分搜索](https://labuladong.online/algo/essential-technique/binary-search-framework/) 或者二叉树相关的数据结构，比如 `TreeMap`，`PriorityQueue` 之类的对吧。

再比如，有时候题目要求你的算法时间复杂度是 O(MN)O(MN)O(MN)，这可以联想到什么？

可以大胆猜测，常规解法是用 [回溯算法](https://labuladong.online/algo/essential-technique/backtrack-framework/) 暴力穷举，但是更好的解法是动态规划，而且是一个二维动态规划，需要一个 `M * N` 的二维 `dp` 数组，所以产生了这样一个时间复杂度。

如果你早就胸有成竹了，那就当我没说，毕竟猜测也不一定准确；但如果你本来就没啥解题思路，那有了这些推测之后，最起码可以给你的思路一些方向吧？

总之，多动脑筋，不放过任何蛛丝马迹，刷题小能手就是你。

* * *

[63\. 不同路径 II](https://leetcode.cn/problems/unique-paths-ii/?show=1)






## 空间压缩

动态规划算法的主要表现形式是带备忘录的递归解法，或者递推的迭代解法，这两种解法本质上都是一样的，效率也差不多。

本文将介绍动态规划迭代写法的一个优势，就是可以将 `dp` 数组进行空间压缩（一般称为滚动数组技巧），降低空间复杂度。

简单说就是，某些情况下状态转移方程仅依赖于相邻的状态，那么就没必要维护整个 `dp` 数组，仅维护所需的几个状态即可，这样可以降低空间复杂度。

但是一般的笔试中对空间的要求并不高，即便不使用这个优化技巧也能通过，所以我个人认为空间压缩并不是必须掌握的技巧，有兴趣的读者可以仔细学习理解一下。



能够使用空间压缩技巧的动态规划一般都是二维 `dp` 问题，**你看它的状态转移方程，如果计算状态 `dp[i][j]` 需要的都是 `dp[i][j]` 相邻的状态，那么就可以使用空间压缩技巧**，将二维的 `dp` 数组转化成一维，将空间复杂度从 O(N^2) 降低到 O(N)。

什么叫「和 `dp[i][j]` 相邻的状态」呢，比如后文 [最长回文子序列](https://labuladong.online/algo/dynamic-programming/subsequence-problem/) 中，最终的代码如下：


cpp 🤖

    #include <string>
    #include <vector>
    #include <algorithm>
    using namespace std;
    
    class Solution {
    public:
        int longestPalindromeSubseq(string s) {
            int n = s.length();
            // dp 数组全部初始化为 0
            vector<vector<int>> dp(n, vector<int>(n, 0));
            // base case
            for (int i = 0; i < n; i++) {
                dp[i][i] = 1;
            }
            // 反着遍历保证正确的状态转移
            for (int i = n - 1; i >= 0; i--) {
                for (int j = i + 1; j < n; j++) {
                    // 状态转移方程
                    if (s[i] == s[j]) {
                        dp[i][j] = dp[i + 1][j - 1] + 2;
                    } else {
                        dp[i][j] = max(dp[i + 1][j], dp[i][j - 1]);
                    }
                }
            }
            // 整个 s 的最长回文子串长度
            return dp[0][n - 1];
        }
    };


Tip

我们本文不探讨如何推状态转移方程，只探讨对二维 DP 问题进行空间压缩的技巧。技巧都是通用的，所以如果你没看过前文，不明白这段代码的逻辑也无妨，完全不会阻碍你学会空间压缩。

你看我们对 `dp[i][j]` 的更新，其实只依赖于 `dp[i+1][j-1], dp[i][j-1], dp[i+1][j]` 这三个状态：

![](https://labuladong.online/algo/images/space-optimal/1.jpeg)

这就叫和 `dp[i][j]` 相邻，反正你计算 `dp[i][j]` 只需要这三个相邻状态，其实根本不需要那么大一个二维的 dp table 对不对？**空间压缩的核心思路就是，将二维数组「投影」到一维数组**：

![](https://labuladong.online/algo/images/space-optimal/2.jpeg)

「投影」这个词应该比较形象吧，说白了就是希望让一维数组发挥原来二维数组的作用。

思路很直观，但是也有一个明显的问题，图中 `dp[i][j-1]` 和 `dp[i+1][j-1]` 这两个状态处在同一列，而一维数组中只能容下一个，那么他俩投影到一维必然有一个会被另一个覆盖掉，我还怎么计算 `dp[i][j]` 呢？

这就是空间压缩的难点，下面就来分析解决这个问题，还是拿「最长回文子序列」问题举例，它的状态转移方程主要逻辑就是如下这段代码：

    for (int i = n - 2; i >= 0; i--) {
        for (int j = i + 1; j < n; j++) {
            // 状态转移方程
            if (s.charAt(i) == s.charAt(j)) {
                dp[i][j] = dp[i + 1][j - 1] + 2;
            } else {
                dp[i][j] = Math.max(dp[i + 1][j], dp[i][j - 1]);
            }
        }
    }

回想上面的图，「投影」其实就是把多行变成一行，所以想把二维 `dp` 数组压缩成一维，一般来说是把第一个维度，也就是 `i` 这个维度去掉，只剩下 `j` 这个维度。**压缩后的一维 `dp` 数组就是之前二维 `dp` 数组的 `dp[i][..]` 那一行**。

我们先将上述代码进行改造，直接无脑去掉 `i` 这个维度，把 `dp` 数组变成一维：

    for (int i = n - 2; i >= 0; i--) {
        for (int j = i + 1; j < n; j++) {
            // 在这里，一维 dp 数组中的数是什么？
            if (s.charAt(i) == s.charAt(j)) {
                dp[j] = dp[j - 1] + 2;
            } else {
                dp[j] = Math.max(dp[j], dp[j - 1]);
            }
        }
    }

上述代码的一维 `dp` 数组只能表示二维 `dp` 数组的一行 `dp[i][..]`。但是我们想得到 `dp[i+1][j-1], dp[i][j-1], dp[i+1][j]` 这几个必要的的值进行状态转移。

因此，我们要先来思考两个问题：

1、在对 `dp[j]` 赋新值之前，`dp[j]` 对应着二维 `dp` 数组中的什么位置？

2、`dp[j-1]` 对应着二维 `dp` 数组中的什么位置？

**对于问题 1，在对 `dp[j]` 赋新值之前，`dp[j]` 的值就是外层 for 循环上一次迭代算出来的值，也就是对应二维 `dp` 数组中 `dp[i+1][j]` 的位置**。

**对于问题 2，`dp[j-1]` 的值就是内层 for 循环上一次迭代算出来的值，也就是对应二维 `dp` 数组中 `dp[i][j-1]` 的位置**。

那么问题已经解决了一大半了，只剩下二维 `dp` 数组中的 `dp[i+1][j-1]` 这个状态我们不能直接从一维 `dp` 数组中得到：

    for (int i = n - 2; i >= 0; i--) {
        for (int j = i + 1; j < n; j++) {
            if (s.charAt(i) == s.charAt(j)) {
                // dp[i][j] = dp[i+1][j-1] + 2;
                dp[j] = ?? + 2;
            } else {
                // dp[i][j] = max(dp[i+1][j], dp[i][j-1]);
                dp[j] = Math.max(dp[j], dp[j - 1]);
            }
        }
    }

因为 for 循环遍历 `i` 和 `j` 的顺序为从左向右，从下向上，所以可以发现，在更新一维 `dp` 数组的时候，`dp[i+1][j-1]` 会被 `dp[i][j-1]` 覆盖掉，图中标出了这四个位置被遍历到的次序：

![](https://labuladong.online/algo/images/space-optimal/3.jpeg)

**那么如果我们想得到 `dp[i+1][j-1]`，就必须在它被覆盖之前用一个临时变量 `temp` 把它存起来，并把这个变量的值保留到计算 `dp[i][j]` 的时候**。为了达到这个目的，结合上图，我们可以这样写代码：

    for (int i = n - 2; i >= 0; i--) {
        // 存储 dp[i+1][j-1] 的变量
        int pre = 0;
        for (int j = i + 1; j < n; j++) {
            int temp = dp[j];
            if (s.charAt(i) == s.charAt(j)) {
                // dp[i][j] = dp[i+1][j-1] + 2;
                dp[j] = pre + 2;
            } else {
                dp[j] = Math.max(dp[j], dp[j - 1]);
            }
            // 到下一轮循环，pre 就是 dp[i+1][j-1] 了
            pre = temp;
        }
    }

别小看这段代码，这是一维 `dp` 最精妙的地方，会者不难，难者不会。为了清晰起见，我用具体的数值来拆解这个逻辑：

假设现在 `i = 5, j = 7` 且 `s[5] == s[7]`，那么现在会进入下面这个逻辑对吧：

    for (int i = 5; i--) {
        for (int j = 7; j++) {
            if (s[5] == s[7]) {
                // dp[5][7] = dp[i+1][j-1] + 2;
                dp[7] = pre + 2;
            }
        }
    }

我问你这个 `pre` 变量是什么？是内层 for 循环上一次迭代的 `temp` 值。

那我再问你**内层** for 循环上一次迭代的 `temp` 值是什么？是 `dp[j-1]` 也就是 `dp[6]`，但请注意，这是**外层** for 循环**上一次迭代**对应的 `dp[6]`，不是现在的 `dp[6]`。

这个要对应二维数组的索引来理解。你现在的 `dp[6]` 是二维 `dp` 数组中的 `dp[i][6] = dp[5][6]`，而人家这个 `temp` 是二维 `dp` 数组中的 `dp[i+1][6] = dp[6][6]`。

也就是说，`pre` 变量就是 `dp[i+1][j-1] = dp[6][6]`，也就是我们想要的结果。

那么现在我们成功对状态转移方程进行了降维打击，算是最硬的的骨头啃掉了，但注意到我们还有 base case 要处理呀：


cpp 🤖

    // dp 数组全部初始化为 0
    vector<vector<int>> dp(n, vector<int>(n, 0));
    // base case
    for (int i = 0; i < n; i++) {
        dp[i][i] = 1;
    }


如何把 base case 也打成一维呢？很简单，记住空间压缩就是投影，我们把 base case 投影到一维看看：

![](https://labuladong.online/algo/images/space-optimal/4.jpeg)

二维 `dp` 数组中的 base case 全都落入了一维 `dp` 数组，不存在冲突和覆盖，所以说我们直接这样写代码就行了：


cpp 🤖

    // base case：一维 dp 数组全部初始化为 1
    vector<int> dp(n, 1);


至此，我们把 base case 和状态转移方程都进行了降维，实际上已经写出完整代码了：


cpp 🤖

    class Solution {
    public:
        int longestPalindromeSubseq(string s) {
            int n = s.length();
            // base case：一维 dp 数组全部初始化为 1
            vector<int> dp(n, 1);
    
            for (int i = n - 2; i >= 0; i--) {
                int pre = 0;
                for (int j = i + 1; j < n; j++) {
                    int temp = dp[j];
                    // 状态转移方程
                    if (s[i] == s[j])
                        dp[j] = pre + 2;
                    else
                        dp[j] = max(dp[j], dp[j - 1]);
                    pre = temp;
                }
            }
            return dp[n - 1];
        }
    };


本文就结束了，不过空间压缩技巧再牛逼，也是基于常规动态规划思路之上的。

你也看到了，使用空间压缩技巧对二维 `dp` 数组进行降维打击之后，解法代码的可读性变得非常差了，如果直接看这种解法，任何人都是一脸懵逼的。算法的优化就是这么一个过程，先写出可读性很好的暴力递归算法，然后尝试运用动态规划技巧优化重叠子问题，最后尝试用空间压缩技巧优化空间复杂度。

也就是说，你最起码能够熟练运用我们前文 [动态规划框架套路详解](https://labuladong.online/algo/essential-technique/dynamic-programming-framework/) 的套路找出状态转移方程，写出一个正确的动态规划解法，然后才有可能观察状态转移的情况，分析是否可能使用空间压缩技巧来优化。

希望读者能够稳扎稳打，层层递进，对于这种比较极限的优化，不做也罢。毕竟套路存于心，走遍天下都不怕！

* * *

**引用本文的题目**


[63\. 不同路径 II](https://leetcode.cn/problems/unique-paths-ii/?show=1)





# 穷举的两种视角


前置知识

阅读本文前，你需要先学习：

*   [二叉树系列算法（纲领篇）](https://labuladong.online/algo/essential-technique/binary-tree-summary/)
*   [动态规划核心框架](https://labuladong.online/algo/essential-technique/dynamic-programming-framework/)
*   [球盒模型：回溯算法穷举的两种视角](https://labuladong.online/algo/practice-in-action/two-views-of-backtrack/)

本文我会带大家复习一下动态规划相关问题的一系列解题套路，然后着重讨论一下动态规划穷举时不同视角的问题。

[动态规划解题组合拳](#)
--------------

首先，[我的刷题心得](https://labuladong.online/algo/essential-technique/algorithm-summary/) 讲了，我们刷的算法问题的本质是「穷举」，动态规划问题也不例外，你必须想办法穷举所有可能的解，然后从中筛选出符合题目要求的解。

另外，动态规划问题穷举的过程中会出现重叠子问题导致的冗余计算，所以前文 [动态规划核心套路框架](https://labuladong.online/algo/essential-technique/dynamic-programming-framework/) 中告诉你如何一步一步把暴力穷举解法优化成效率更高的动态规划解法。

然而，想要写出暴力解需要依据状态转移方程，状态转移方程是动态规划的解题核心，可不是那么容易想出来的。不过，前文 [动态规划设计：数学归纳法](https://labuladong.online/algo/dynamic-programming/longest-increasing-subsequence/) 告诉你，思考状态转移方程的一个基本方法是数学归纳法，即明确 `dp` 函数或数组的定义，然后使用这个定义，从已知的「状态」中推导出未知的「状态」。

**接下来就是本文要着重探讨的问题了：就算 `dp` 函数/数组的定义相同，如果你使用不同的「视角」进行穷举，效率也不见得是相同的**。

关于穷举「视角」的问题，前文 [球盒模型：回溯算法穷举的两种视角](https://labuladong.online/algo/practice-in-action/two-views-of-backtrack/) 讲了回溯算法中不同的穷举视角导致的不同解法，其实这种视角的切换在动态规划类型问题中依然存在。前文对排列的举例非常有助于你理解穷举视角的问题，这里再简单提一下。


[排列问题的两种视角](#)
--------------

我们先回顾一下以前学过的排列组合知识：

1、`P(n, k)`（也有很多书写成 `A(n, k)`）表示从 `n` 个不同元素中拿出 `k` 个元素的排列（Permutation/Arrangement）；`C(n, k)` 表示从 `n` 个不同元素中拿出 `k` 个元素的组合（Combination）总数。

2、「排列」和「组合」的主要区别在于是否考虑顺序的差异。

3、排列和组合总数的计算公式如下：

![](https://labuladong.online/algo/images/set-split/math.png)

好，现在我问一个问题，这个排列公式 `P(n, k)` 是如何推导出来的？为了搞清楚这个问题，我需要讲一点组合数学的知识。

排列组合问题的各种变体都可以抽象成「球盒模型」，`P(n, k)` 就可以抽象成下面这个场景：

![](https://labuladong.online/algo/images/set-split/7.jpeg)

即，将 `n` 个标记了不同序号的球（标号为了体现顺序的差异），放入 `k` 个标记了不同序号的盒子中（其中 `n >= k`，每个盒子最终都装有恰好一个球），共有 `P(n, k)` 种不同的方法。

现在你来，往盒子里放球，你怎么放？其实有两种视角。

**首先，你可以站在盒子的视角**，每个盒子必然要选择一个球。

这样，第一个盒子可以选择 `n` 个球中的任意一个，然后你需要让剩下 `k - 1` 个盒子在 `n - 1` 个球中选择：

![](https://labuladong.online/algo/images/set-split/8.jpeg)

**另外，你也可以站在球的视角**，因为并不是每个球都会被装进盒子，所以球的视角分两种情况：

1、第一个球可以不装进任何一个盒子，这样的话你就需要将剩下 `n - 1` 个球放入 `k` 个盒子。

2、第一个球可以装进 `k` 个盒子中的任意一个，这样的话你就需要将剩下 `n - 1` 个球放入 `k - 1` 个盒子。

结合上述两种情况，可以得到：

![](https://labuladong.online/algo/images/set-split/9.jpeg)

你看，两种视角得到两个不同的递归式，但这两个递归式解开的结果都是我们熟知的阶乘形式：

![](https://labuladong.online/algo/images/set-split/math1.png)

至于如何解递归式，涉及数学的内容比较多，这里就不做深入探讨了，有兴趣的读者可以自行学习组合数学相关知识。

当然，以上只是纯数学的推导，`P(n, k)` 的计算结果也仅仅是一个数字，所以以上两种穷举视角从数学上讲没什么差异。但从编程的角度来看，如果让你计算出来所有排列结果，那么两种穷举思路的代码实现可能会产生性能上的差异，因为有的穷举思路难免会使用额外的 for 循环拖慢效率，这也是前文 [球盒模型理解回溯算法的两种视角](https://labuladong.online/algo/practice-in-action/two-views-of-backtrack/) 主要探讨的。

本文不讲回溯算法和排列组合，不过请你记住这个例子，待会会把这种穷举视角的差异运用到动态规划题目当中。

[例题分析](#)
---------

看一下力扣第 115 题「[不同的子序列](https://leetcode.cn/problems/distinct-subsequences/)」：

**115\. 不同的子序列** | [力扣](https://leetcode.cn/problems/distinct-subsequences/) | [LeetCode](https://leetcode.com/problems/distinct-subsequences/) |  🔴

给你两个字符串 `s` 和 `t` ，统计并返回在 `s` 的 **子序列** 中 `t` 出现的个数，结果需要对 109 + 7 取模。

**示例 1：**

**输入：**s = "rabbbit", t = "rabbit"
`**输出**`**：**`3`
**解释：**
如下所示, 有 3 种可以从 s 中得到 `"rabbit" 的方案`。
`**rabb**b**it**`
`**ra**b**bbit**`
`**rab**b**bit**`

**示例 2：**

**输入：**s = "babgbag", t = "bag"
`**输出**`**：**`5`
**解释：**
如下所示, 有 5 种可以从 s 中得到 `"bag" 的方案`。 
`**ba**b**g**bag`
`**ba**bgba**g**`
`**b**abgb**ag**`
`ba**b**gb**ag**`
`babg**bag**`

**提示：**

*   `1 <= s.length, t.length <= 1000`
*   `s` 和 `t` 由英文字母组成

**题目来源：[力扣 115. 不同的子序列](https://leetcode.cn/problems/distinct-subsequences/)。**

函数签名如下：


cpp 🤖

    int numDistinct(string s, string t);

你要数一数 `s` 的子序列中有多少个 `t`，说白了就是穷举嘛，那么首先想到的就是能不能把原问题分解成规模更小的子问题，然后通过子问题的答案推导出原问题的答案。

首先，我们可以这样定义一个 `dp` 函数：


cpp 🤖

    // 定义：s[i..] 的子序列中 t[j..] 出现的次数为 dp(s, i, t, j)
    int dp(string s, int i, string t, int j)


这道题对 `dp` 函数的定义很简单直接，题目让你求出现次数，那你就定义函数返回值为出现次数就可以。

有了这个 `dp` 函数，题目想要的结果是 `dp(s, 0, t, 0)`，base case 也很容易写出来，解法框架如下：


cpp 🤖

    int numDistinct(string s, string t) {
        return dp(s, 0, t, 0);
    }
    
    // 定义：s[i..] 的子序列中 t[j..] 出现的次数为 dp(s, i, t, j)
    int dp(string s, int i, string t, int j) {
        // base case 1
        if (j == t.length()) {
            // t 已经全部匹配完成
            return 1;
        }
        // base case 2
        if (s.length() - i < t.length() - j) {
            // s[i..] 比 t[j..] 还短，必然没有匹配的子序列
            return 0;
        }
    
        // ...
    }



好，接下来开始思考如何利用这个 `dp` 函数将大问题分解成小问题，即如何写出状态转移方程进行穷举。

**回顾一下之前讲的排列组合的「球盒模型」，这里是不是很类似？`t` 中的若干字符就好像若干盒子，`s` 中的若干字符就好像若干小球，你需要做的就是给所有盒子都装一个小球。所以这里就有两种穷举思路了，分别是站在 `t` 的视角（盒子选择小球）和站在 `s` 的视角（小球选择盒子）**。

[视角一，从 `t` 的视角穷举](#)
--------------------

我们的原问题是求 `s[0..]` 的所有子序列中 `t[0..]` 出现的次数，那么可以先看 `t[0]` 在 `s` 中的什么位置，假设 `s[2], s[6]` 是字符 `t[0]`，那么原问题转化成了在 `s[3..]` 和 `s[7..]` 的所有子序列中计算 `t[1..]` 出现的次数。

写成比较偏数学的形式就是状态转移方程：

    // 定义：s[i..] 的子序列中 t[j..] 出现的次数为 dp(s, i, t, j)
    dp(s, i, t, j) = SUM( dp(s, k + 1, t, j + 1) where k >= i and s[k] == t[j] )

翻译成代码大致就是这个思路：


cpp 🤖

    // 定义：s[i..] 的子序列中 t[j..] 出现的次数为 dp(s, i, t, j)
    int dp(string s, int i, string t, int j) {
        int res = 0;
        // 在 s[i..] 中寻找 k，使得 s[k] == t[j]
        for (int k = i; k < s.length(); k++) {
            if (s[k] == t[j]) {
                // 累加结果
                res += dp(s, k + 1, t, j + 1);
            }
        }
        return res;
    }


这个思路应该不难理解吧，当然还可以加上备忘录消除重叠子问题，最终解法如下：

cpp 🤖

    class Solution {
        // 备忘录
        vector<vector<int>> memo;
    
        int numDistinct(string s, string t) {
            // 初始化备忘录为特殊值 -1
            memo = vector<vector<int>>(s.length(), vector<int>(t.length(), -1));
            return dp(s, 0, t, 0);
        }
    
        // 定义：s[i..] 的子序列中 t[j..] 出现的次数为 dp(s, i, t, j)
        int dp(string s, int i, string t, int j) {
            // base case 1
            if (j == t.length()) {
                return 1;
            }
            // base case 2
            if (s.length() - i < t.length() - j) {
                return 0;
            }
            // 查备忘录防止冗余计算
            if (memo[i][j] != -1) {
                return memo[i][j];
            }
            int res = 0;
            // 执行状态转移方程
            // 在 s[i..] 中寻找 k，使得 s[k] == t[j]
            for (int k = i; k < s.length(); k++) {
                if (s[k] == t[j]) {
                    // 累加结果
                    res += dp(s, k + 1, t, j + 1);
                }
            }
            // 存入备忘录
            memo[i][j] = res;
            return res;
        }
    };


这道题就解决了，不过效率不算很高，我们可以粗略估算一下这个算法的时间复杂度上界，其中 `M, N` 分别代表 `s, t` 的长度，算法的「状态」就是 `dp` 函数参数 `i, j` 的组合：

      带备忘录的动态规划算法的时间复杂度 
    = 子问题的个数 x 函数本身的时间复杂度 
    = 「状态」的个数 x 函数本身的时间复杂度 
    = O(MN) * O(M)
    = O(N * M^2)

当然，因为 for 循环的复杂度不总是 O(M) 且子问题个数肯定小于 O(MN)，所以这是复杂度的粗略上界。不过根据前文 [算法时空复杂度使用指南](https://labuladong.online/algo/essential-technique/complexity-analysis/) 的描述，这个上界还是说明这个算法的复杂度有些偏高。主要高在哪里呢？对「状态」的穷举已经有了 `memo` 备忘录的优化，所以 O(MN) 的复杂度是必不可少的，关键问题出在 `dp` 函数中的 for 循环。

是否可以优化掉 `dp` 函数中的 for 循环呢？可以的，这就需要另一种穷举视角来解决这个问题。

[视角二，从 `s` 的视角穷举](#)
--------------------

我们的原问题是计算 `s[0..]` 的所有子序列中 `t[0..]` 出现的次数，可以先看看 `s[0]` 是否能匹配 `t[0]`，如果不匹配，那没得说，原问题就可以转化为计算 `s[1..]` 的所有子序列中 `t[0..]` 出现的次数；

但如果 `s[0]` 可以匹配 `t[0]`，那么又有两种情况，这两种情况是累加的关系：

1、让 `s[0]` 匹配 `t[0]`，那么原问题转化为在 `s[1..]` 的所有子序列中计算 `t[1..]` 出现的次数。

2、不让 `s[0]` 匹配 `t[0]`，那么原问题转化为在 `s[1..]` 的所有子序列中计算 `t[0..]` 出现的次数。

为啥明明 `s[0]` 可以匹配 `t[0]`，还不让它俩匹配呢？主要是为了给 `s[0]` 之后的元素匹配的机会，比如 `s = "aab", t = "ab"`，就有两种匹配方式：`a_b` 和 `_ab`。

把以上思路写成状态转移方程：


cpp 🤖

    // 定义：s[i..] 的子序列中 t[j..] 出现的次数为 dp(s, i, t, j)
    int dp(string s, int i, string t, int j) {
        if (s[i] == t[j]) {
            // 匹配，两种情况，累加关系
            return dp(s, i + 1, t, j + 1) + dp(s, i + 1, t, j);
        } else {
            // 不匹配，在 s[i+1..] 的子序列中计算 t[j..] 的出现次数
            return dp(s, i + 1, t, j);
        }
    }


依照这个思路，再加个备忘录消除重叠子问题，可以写出如下解法：


cpp 🤖

    class Solution {
        vector<vector<int>> memo;
    
    public:
        int numDistinct(string s, string t) {
            // 初始化备忘录为特殊值 -1
            memo = vector<vector<int>>(s.length(), vector<int>(t.length(), -1));
            return dp(s, 0, t, 0);
        }
    
        // 定义：s[i..] 的子序列中 t[j..] 出现的次数为 dp(s, i, t, j)
        int dp(string& s, int i, string& t, int j) {
            // base case 1
            if (j == t.length()) {
                return 1;
            }
            // base case 2
            if (s.length() - i < t.length() - j) {
                return 0;
            }
            // 查备忘录防止冗余计算
            if (memo[i][j] != -1) {
                return memo[i][j];
            }
            int res = 0;
            // 执行状态转移方程
            if (s[i] == t[j]) {
                // 匹配，两种情况，累加关系
                res = dp(s, i + 1, t, j + 1) + dp(s, i + 1, t, j);
            } else {
                // 不匹配，在 s[i+1..] 的子序列中计算 t[j..] 的出现次数
                res = dp(s, i + 1, t, j);
            }
            // 结果存入备忘录
            memo[i][j] = res;
            return res;
        }
    };


这个解法中 `dp` 函数递归的次数，即状态 `i, j` 的不同组合的个数为 O(MN)，而 `dp` 函数本身没有 for 循环，即时间复杂度为 O(1)，所以算法总的时间复杂度就是 O(MN)，比刚才的解法要好一些，你提交这个解法代码，耗时明显比刚才的解法少一些。

至此，这道题就分析完了。我们分别站在 `t` 的视角和 `s` 的视角运用 `dp` 函数的定义进行穷举，得出两种完全不同但都是正确的状态转移逻辑，不过两种逻辑在代码实现上有效率的差异。

那么不妨进一步思考一下，什么样的动态规划题目可能产生「穷举视角」上的差异？换句话说，什么样的动态规划问题能够抽象成经典的「球盒模型」呢？如果你有思考，欢迎留言和我探讨。

* * *

**引用本文的题目**


[剑指 Offer II 097. 子序列的数目](https://leetcode.cn/problems/21dk04/?show=1)

# 动态规划与回溯思维转变

前置知识

阅读本文前，你需要先学习：

*   [二叉树系列算法（纲领篇）](https://labuladong.online/algo/essential-technique/binary-tree-summary/)
*   [动态规划核心框架](https://labuladong.online/algo/essential-technique/dynamic-programming-framework/)

之前 [手把手带你刷二叉树（纲领篇）](https://labuladong.online/algo/essential-technique/binary-tree-summary/) 把递归穷举划分为「遍历」和「分解问题」两种思路，其中「遍历」的思路扩展延伸一下就是 [回溯算法](https://labuladong.online/algo/essential-technique/backtrack-framework/)，「分解问题」的思路可以扩展成 [动态规划算法](https://labuladong.online/algo/essential-technique/dynamic-programming-framework/)。

这种思维转换不止局限于二叉树相关的算法，本文就跳出二叉树类型问题，来看看实际算法题中如何把问题抽象成树形结构，见招拆招逐步优化，从而进行「遍历」和「分解问题」的思维转换，从回溯算法顺滑地切换到动态规划算法。

先说句题外话，前文 [动态规划核心框架详解](https://labuladong.online/algo/essential-technique/dynamic-programming-framework/) 说，**标准的动态规划问题一定是求最值的**，因为动态规划类型问题有一个性质叫做「最优子结构」，即从子问题的最优解推导出原问题的最优解。

但在我们平常的语境中，就算不是求最值的题目，只要看见使用备忘录消除重叠子问题，我们一般都称它为动态规划算法。严格来讲这是不符合动态规划问题的定义的，说这种解法叫做「带备忘录的 DFS 算法」可能更准确些。不过咱也不用太纠结这种名词层面的细节，既然大家叫的顺口，就叫它动态规划也无妨。

本文讲解的两道题目也不是求最值的，但依然会把他们的解法称为动态规划解法，这里提前跟大家说下这个变通，免得严谨的读者疑惑。其他不多说了，直接看题目吧。


[单词拆分 I](#)
-----------

首先看下力扣第 139 题「[单词拆分](https://leetcode.cn/problems/word-break/)」：

**139\. 单词拆分** | [力扣](https://leetcode.cn/problems/word-break/) | [LeetCode](https://leetcode.com/problems/word-break/) |  🟠

给你一个字符串 `s` 和一个字符串列表 `wordDict` 作为字典。如果可以利用字典中出现的一个或多个单词拼接出 `s` 则返回 `true`。

**注意：**不要求字典中出现的单词全部都使用，并且字典中的单词可以重复使用。

**示例 1：**

**输入:** s = "leetcode", wordDict = \["leet", "code"\]
**输出:** true
**解释:** 返回 true 因为 "leetcode" 可以由 "leet" 和 "code" 拼接成。

**示例 2：**

**输入:** s = "applepenapple", wordDict = \["apple", "pen"\]
**输出:** true
**解释:** 返回 true 因为 "applepenapple" 可以由 "apple" "pen" "apple" 拼接成。
     注意，你可以重复使用字典中的单词。

**示例 3：**

**输入:** s = "catsandog", wordDict = \["cats", "dog", "sand", "and", "cat"\]
**输出:** false

**提示：**

*   `1 <= s.length <= 300`
*   `1 <= wordDict.length <= 1000`
*   `1 <= wordDict[i].length <= 20`
*   `s` 和 `wordDict[i]` 仅由小写英文字母组成
*   `wordDict` 中的所有字符串 **互不相同**

**题目来源：[力扣 139. 单词拆分](https://leetcode.cn/problems/word-break/)。**

函数签名如下：


cpp 🤖

    bool wordBreak(string s, vector<string>& wordDict);


这是一道非常高频的面试题，我们来思考下如何通过「遍历」和「分解问题」的思路来解决它。

### [遍历的思路（回溯解法）](#)

**先说说「遍历」的思路，也就是用回溯算法解决本题**。回溯算法最经典的应用就是排列组合相关的问题了，不难发现这道题换个说法也可以变成一个排列问题：

现在给你一个不包含重复单词的单词列表 `wordDict` 和一个字符串 `s`，请你判断是否可以从 `wordDict` 中选出若干单词的排列（可以重复挑选）构成字符串 `s`。

这就是前文 [回溯算法秒杀排列组合问题的九种变体](https://labuladong.online/algo/essential-technique/permutation-combination-subset-all-in-one/) 中讲到的最后一种变体：元素无重可复选的排列问题，前文我写了一个 `permuteRepeat` 函数，代码如下：


cpp 🤖

    class Solution {
    public:
        vector<vector<int>> res;
        deque<int> track;
    
        vector<vector<int>> permuteRepeat(vector<int>& nums) {
            backtrack(nums);
            return res;
        }
    
        // 回溯算法核心函数
        void backtrack(vector<int>& nums) {
            // base case，到达叶子节点
            if (track.size() == nums.size()) {
                // 收集叶子节点上的值
                res.push_back(vector<int>(track.begin(), track.end()));
                return;
            }
    
            // 回溯算法标准框架
            for (int i = 0; i < nums.size(); i++) {
                // 做选择
                track.push_back(nums[i]);
                // 进入下一层回溯树
                backtrack(nums);
                // 取消选择
                track.pop_back();
            }
        }
    };

给这个函数输入 `nums = [1,2,3]`，输出是 3^3 = 27 种可能的组合：

    [
      [1,1,1],[1,1,2],[1,1,3],[1,2,1],[1,2,2],[1,2,3],[1,3,1],[1,3,2],[1,3,3],
      [2,1,1],[2,1,2],[2,1,3],[2,2,1],[2,2,2],[2,2,3],[2,3,1],[2,3,2],[2,3,3],
      [3,1,1],[3,1,2],[3,1,3],[3,2,1],[3,2,2],[3,2,3],[3,3,1],[3,3,2],[3,3,3]
    ]

这段代码实际上就是遍历一棵高度为 `N + 1` 的满 `N` 叉树（`N` 为 `nums` 的长度），其中根到叶子的每条路径上的元素就是一个排列结果：

![](https://labuladong.online/algo/images/word-break/1.jpeg)

类比一下，本文讲的这道题也有异曲同工之妙，假设 `wordDict = ["a", "aa", "ab"], s = "aaab"`，想用 `wordDict` 中的单词拼出 `s`，其实也面对着类似的一棵 `M` 叉树，`M` 为 `wordDict` 中单词的个数，**你需要做的就是站在回溯树的每个节点上，看看哪个单词能够匹配 `s[i..]` 的前缀，从而判断应该往哪条树枝上走**：

![](https://labuladong.online/algo/images/word-break/2.jpeg)

然后，按照前文 [回溯算法框架详解](https://labuladong.online/algo/essential-technique/backtrack-framework/) 所说，你把 `backtrack` 函数理解成在回溯树上游走的一个指针，维护每个节点上的变量 `i`，即可遍历整棵回溯树，寻找出匹配 `s` 的组合。

回溯算法解法代码如下：


cpp 🤖

    class Solution {
    private:
        vector<string> wordDict;
        // 记录是否找到一个合法的答案
        bool found = false;
        // 记录回溯算法的路径
        deque<string> track;
    
    public:
        // 主函数
        bool wordBreak(string s, vector<string>& wordDict) {
            this->wordDict = wordDict;
            // 执行回溯算法穷举所有可能的组合
            backtrack(s, 0);
            return found;
        }
    
        // 回溯算法框架
        void backtrack(string& s, int i) {
            // base case
            if (found) {
                // 如果已经找到答案，就不要再递归搜索了
                return;
            }
            if (i == s.size()) {
                // 整个 s 都被匹配完成，找到一个合法答案
                found = true;
                return;
            }
    
            // 回溯算法框架
            for (string& word : wordDict) {
                // 看看哪个单词能够匹配 s[i..] 的前缀
                int len = word.size();
                if (i + len <= s.size()
                    && s.substr(i, len) == word) {
                    // 找到一个单词匹配 s[i..i+len)
                    // 做选择
                    track.push_back(word);
                    // 进入回溯树的下一层，继续匹配 s[i+len..]
                    backtrack(s, i + len);
                    // 撤销选择
                    track.pop_back();
                }
            }
        }
    };


这段代码就是严格按照回溯算法框架写出来的，应该不难理解，但这段代码无法通过所有测试用例，我们按照 [算法时空复杂度使用指南](https://labuladong.online/algo/essential-technique/complexity-analysis/) 中讲到的方法来分析一下它的时间复杂度。

递归函数的时间复杂度的粗略估算方法就是用递归函数调用次数（递归树的节点数） x 递归函数本身的复杂度。对于这道题来说，递归树的每个节点其实就是对 `s` 进行的一次切割，那么最坏情况下 `s` 能有多少种切割呢？长度为 `N` 的字符串 `s` 中共有 `N - 1` 个「缝隙」可供切割，每个缝隙可以选择「切」或者「不切」，所以 `s` 最多有 O(2N)O(2^N)O(2N) 种切割方式，即递归树上最多有 O(2N)O(2^N)O(2N) 个节点。

当然，实际情况可定会好一些，毕竟存在剪枝逻辑，但从最坏复杂度的角度来看，递归树的节点个数确实是指数级别的。

那么 `backtrack` 函数本身的时间复杂度是多少呢？主要的时间消耗是遍历 `wordDict` 寻找匹配 `s[i..]` 的前缀的单词：

cpp 🤖

    // 遍历 wordDict 的所有单词
    for (string word : wordDict) {
        // 看看哪个单词能够匹配 s[i..] 的前缀
        int len = word.length();
        if (i + len <= s.length()
            && s.substr(i, len) == word) {
            // 找到一个单词匹配 s[i..i+len)
            // ...
        }
    }


设 `wordDict` 的长度为 `M`，字符串 `s` 的长度为 `N`，那么这段代码的最坏时间复杂度是 O(MN)O(MN)O(MN)（for 循环 O(M)O(M)O(M)，Java 的 `substring` 方法 O(N)O(N)O(N)），所以总的时间复杂度是 O(2N∗MN)O(2^N \* MN)O(2N∗MN)。

这里顺便说一个细节优化，其实你也可以反过来，通过穷举 `s[i..]` 的前缀去判断 `wordDict` 中是否有对应的单词：


cpp 🤖

    // 注意，要转换为 unordered_set，提高 count 方法的效率
    unordered_set<string> wordDict(wordDict.begin(), wordDict.end()); 
    
    // 遍历 s[i..] 的所有前缀
    for (int len = 1; i + len <= s.length(); len++) {
        // 看看 wordDict 中是否有单词能匹配 s[i..] 的前缀
        string prefix = s.substr(i, len);
        if (wordDict.count(prefix)) {
            // 找到一个单词匹配 s[i..i+len)
            // ...
        }
    }


这段代码和刚才那段代码的结果是一样的，但这段代码的时间复杂度变成了 O(N2)O(N^2)O(N2)，和刚才的代码不同。

到底哪样子好呢？这要看题目给的数据范围。本题说了 `1 <= s.length <= 300, 1 <= wordDict.length <= 1000`，所以 O(N2)O(N^2)O(N2) 的结果较小，这段代码的实际运行效率应该稍微高一些，这个是一个细节的优化，你可以自己做一下，我就不写了。

不过即便你优化这段代码，总的时间复杂度依然是指数级的 O(2N∗N2)O(2^N \* N^2)O(2N∗N2)，是无法通过所有测试用例的，那么问题出在哪里呢？

比如输入 `wordDict = ["a", "aa", "b"], s = "aaab"`，你注意回溯算法穷举时会存在重复的情况：

![](https://labuladong.online/algo/images/word-break/3.jpeg)

图中标红的这两部分，虽然经历了不同的切分，但是切分得出的结果是相同的 `"aab"`，所以这两个节点下面的子树也是重复的，即存在冗余计算，这也是这个算法复杂度为指数级别的原因。

### [利用后序位置优化](#)

不管是什么算法，消除冗余计算的方法就是加备忘录。回溯算法也可以加备忘录，我们可以称之为「剪枝」，即把冗余的子树给它剪掉。

就比如面对这个 `"aab"` 子串的局面，我希望让备忘录告诉我，这个 `"aab"` 到底能不能被成功切分？如果之前尝试过不能切分的话，我就直接跳过，不用遍历子树去穷举切分了，从而优化效率。如果之前尝试过能成功切分的话，那也不关备忘录什么事情了，因为 `found == true` 本身就是个 base case，整个递归都会被终止。

正如 [二叉树/递归系列算法通用心法](https://labuladong.online/algo/essential-technique/binary-tree-summary/) 对前序/后序位置的分析，要想让备忘录做到这一点，需要在后序位置上更新备忘录，因为这个 `"aab"` 其实是一棵子树，对吧？**你需要在遍历完子树的时候，在备忘录中记录下该子树是否可以被成功切分**。

回溯函数 `backtrack` 为遍历而生，本身没有返回值，即没有从子树传递回来的信息。但针对这道题，我们还是有办法的，因为这不是有个外部变量 `found` 吗？这个变量就可以告诉我们子树是否能够成功切分：

**如果 `found` 为 false，说明还没找到一个成功的切分，也就间接说明当前子树不能成功切分**。此时我们可以在备忘录里面记一笔，从而消除掉冗余的穷举。

具体到代码上，只需稍加修改，即可实现备忘录功能：


cpp 🤖

    class Solution {
    
    private:
        // 备忘录，存储不能切分的子串（子树），从而避免重复计算
        unordered_set<string> memo;
    
        // ...
    
        void backtrack(string& s, int i) {
            if (found) {
                return;
            }
            if (i == s.size()) {
                found = true;
                return;
            }
    
            // 新增的剪枝逻辑，查询子串（子树）是否已经计算过
            string suffix = s.substr(i);
            if (memo.count(suffix)) {
                // 当前子串（子树）不能被切分，就不用继续递归了
                return;
            }
    
            for (string& word : wordDict) {
                // ...
            }
    
            // 后序位置，将不能切分的子串（子树）记录到备忘录
            if (!found) {
                memo.insert(suffix);
            }
        }
    };


### [分解问题的思路（动态规划）](#)

上面能用回溯算法解决这个问题，其实还是这道题比较简单，我们可以借助 `found` 变量在后序位置更新备忘录，你会看到后面讲的单词拆分 II 就不能这么搞了。

要在后序位置更新备忘录存储子树的答案，一般还是要借助递归函数的返回值，因此还是要用「分解问题」的思维模式。

我们刚才以排列组合的视角思考这个问题，现在我们换一种视角，思考一下是否能够把原问题分解成规模更小，结构相同的子问题，然后通过子问题的结果计算原问题的结果。

对于输入的字符串 `s`，如果我能够从单词列表 `wordDict` 中找到一个单词匹配 `s` 的前缀 `s[0..k]`，那么只要我能拼出 `s[k+1..]`，就一定能拼出整个 `s`。换句话说，我把规模较大的原问题 `wordBreak(s[0..])` 分解成了规模较小的子问题 `wordBreak(s[k+1..])`，然后通过子问题的解反推出原问题的解。

有了这个思路就可以定义一个 `dp` 函数，并给出该函数的定义：


cpp 🤖

    // 定义：返回 s[i..] 是否能够被拼出
    int dp(string s, int i);
    
    // 计算整个 s 是否能被拼出，调用 dp(s, 0)


有了这个函数定义，就可以把刚才的逻辑大致翻译成伪码：


cpp 🤖

    vector<string> wordDict;
    
    // 定义：返回 s[i..] 是否能够被拼出
    int dp(string s, int i) {
        // base case，s[i..] 是空串
        if (i == s.length()) {
            return true;
        }
        // 遍历 wordDict，看看哪些单词是 s[i..] 的前缀
        for (string word : wordDict) {
            // word 是 s[i..] 的前缀
            if (s.substr(i, word.length()) == word) {
                int len = word.length();
                // 只要 s[i+len..] 可以被拼出，s[i..] 就能被拼出
                if (dp(s, i + len) == true) {
                    return true;
                }
            }
        }
        // 所有单词都尝试过，无法拼出整个 s
        return false;
    }


类似之前讲的回溯算法，`dp` 函数中的 for 循环也可以优化一下：


cpp 🤖

    // 注意，用哈希集合快速判断元素是否存在
    unordered_set<string> wordDict;
    
    // 定义：返回 s[i..] 是否能够被拼出
    int dp(string s, int i) {
        // base case，s[i..] 是空串
        if (i == s.length()) {
            return true;
        }
        
        // 遍历 s[i..] 的所有前缀，看看哪些前缀存在 wordDict 中
        for (int len = 1; i + len <= s.length(); len++) {
            // wordDict 中存在 s[i..len)
            if(wordDict.count(s.substr(i, len)) > 0) {
                // 只要 s[i+len..] 可以被拼出，s[i..] 就能被拼出
                if (dp(s, i + len) == true) {
                    return true;
                }
            }
        }
        // 所有单词都尝试过，无法拼出整个 s
        return false;
    }


对于这个 `dp` 函数，指针 `i` 的位置就是「状态」，所以我们可以通过添加备忘录的方式优化效率，避免对相同的子问题进行冗余计算。最终的解法代码如下：


cpp 🤖

    class Solution {
    private:
        // 用哈希集合方便快速判断是否存在
        unordered_set<string> wordDict;
        // 备忘录，-1 代表未计算，0 代表无法凑出，1 代表可以凑出
        vector<int> memo;
    
    public:
        // 主函数
        bool wordBreak(string s, vector<string>& wordDict) {
            // 转化为哈希集合，快速判断元素是否存在
            for (auto word : wordDict) {
                this->wordDict.insert(word);
            }
            // 备忘录初始化为 -1
            memo.resize(s.length(), -1);
            return dp(s, 0);
        }
    
        // 定义：s[i..] 是否能够被拼出
        bool dp(const string& s, int i) {
            // base case
            if (i == s.length()) {
                return true;
            }
            // 防止冗余计算
            if (memo[i] != -1) {
                return memo[i] == 0 ? false : true;
            }
    
            // 遍历 s[i..] 的所有前缀
            for (int len = 1; i + len <= s.length(); len++) {
                // 看看哪些前缀存在 wordDict 中
                string prefix = s.substr(i, len);
                if (wordDict.count(prefix)) {
                    // 找到一个单词匹配 s[i..i+len)
                    // 只要 s[i+len..] 可以被拼出，s[i..] 就能被拼出
                    bool subProblem = dp(s, i + len);
                    if (subProblem == true) {
                        memo[i] = 1;
                        return true;
                    }
                }
            }
            // s[i..] 无法被拼出
            memo[i] = 0;
            return false;
        }
    };


还可以再优化

注意到计算 `prefix` 的过程中，我们是直接调用编程语言提供的子串截取函数，这个函数的时间复杂度是 O(N)O(N)O(N)。不难发现截取子串的开始索引是固定的 `i`，结束索引是递增的 `j`，所以我们手动维护这个 `prefix` 子串，避免调用子串截取函数，进一步提高效率。这个小优化就留给你来做吧。


这个解法能够通过所有测试用例，我们根据 [算法时空复杂度使用指南](https://labuladong.online/algo/essential-technique/complexity-analysis/) 来算一下它的时间复杂度：

因为有备忘录的辅助，消除了递归树上的重复节点，使得递归函数的调用次数从指数级别降低为状态的个数 O(N)O(N)O(N)，函数本身的复杂度还是 O(N2)O(N^2)O(N2)，所以总的时间复杂度是 O(N3)O(N^3)O(N3)，相较回溯算法的效率有大幅提升。

[单词拆分 II](#)
------------

有了上一道题的铺垫，力扣第 140 题「[单词拆分 II](https://leetcode.cn/problems/word-break-ii/)」就容易多了，先看下题目：

**140\. 单词拆分 II** | [力扣](https://leetcode.cn/problems/word-break-ii/) | [LeetCode](https://leetcode.com/problems/word-break-ii/) |  🔴

给定一个字符串 `s` 和一个字符串字典 `wordDict` ，在字符串 `s` 中增加空格来构建一个句子，使得句子中所有的单词都在词典中。**以任意顺序** 返回所有这些可能的句子。

**注意：**词典中的同一个单词可能在分段中被重复使用多次。

**示例 1：**

**输入:**s = "catsanddog", wordDict = \["cat","cats","and","sand","dog"\]
**输出:**\["cats and dog","cat sand dog"\]

**示例 2：**

**输入:**s = "pineapplepenapple", wordDict = \["apple","pen","applepen","pine","pineapple"\]
**输出:**\["pine apple pen apple","pineapple pen apple","pine applepen apple"\]
**解释:** 注意你可以重复使用字典中的单词。

**示例 3：**

**输入:**s = "catsandog", wordDict = \["cats","dog","sand","and","cat"\]
**输出:**\[\]

**提示：**

*   `1 <= s.length <= 20`
*   `1 <= wordDict.length <= 1000`
*   `1 <= wordDict[i].length <= 10`
*   `s` 和 `wordDict[i]` 仅有小写英文字母组成
*   `wordDict` 中所有字符串都 **不同**

**题目来源：[力扣 140. 单词拆分 II](https://leetcode.cn/problems/word-break-ii/)。**

相较上一题，这道题不是单单问你 `s` 是否能被拼出，还要问你是怎么拼的，其实只要把之前的解法稍微改一改就可以解决这道题。

### [遍历的思路（回溯算法）](#)

上一道题的回溯算法维护一个 `found` 变量，只要找到一种拼接方案就提前结束遍历回溯树，那么在这道题中我们不要提前结束遍历，并把所有可行的拼接方案收集起来就能得到答案：


cpp 🤖

    class Solution {
    public:
        // 记录结果
        vector<string> res;
        // 记录回溯算法的路径
        vector<string> track;
        vector<string> wordDict;
    
        // 主函数
        vector<string> wordBreak(string s, vector<string>& wordDict) {
            this->wordDict = wordDict;
            // 执行回溯算法穷举所有可能的组合
            backtrack(s, 0);
            return res;
        }
    
        // 回溯算法框架
        void backtrack(string& s, int i) {
            // base case
            if (i == s.size()) {
                // 找到一个合法组合拼出整个 s，转化成字符串
                string temp = "";
                for(int k = 0; k < track.size(); k++){
                    temp += track[k];
                    if(k != track.size()-1){
                        temp += " ";
                    }
                }
                res.push_back(temp);
                return;
            }
    
            // 回溯算法框架
            for (auto word : wordDict) {
                // 看看哪个单词能够匹配 s[i..] 的前缀
                int len = word.size();
                if (i + len <= s.size()
                    && s.substr(i, len) == word) {
                    // 找到一个单词匹配 s[i..i+len)
                    // 做选择
                    track.push_back(word);
                    // 进入回溯树的下一层，继续匹配 s[i+len..]
                    backtrack(s, i + len);
                    // 撤销选择
                    track.pop_back();
                }
            }
        }
    };


这个解法的时间复杂度和前一道题类似，依然是 O(2N∗MN)O(2^N \* MN)O(2N∗MN)，但由于这道题给的数据规模较小，所以可以通过所有测试用例。

### [是否可以利用后序位置优化？](#)

和之前类似，这个解法还是有优化空间的，依然是这种情况：

![](https://labuladong.online/algo/images/word-break/3.jpeg)

对于重复的子树，依然会造成没有必要的重复遍历，我们依然可以通过备忘录的方式进行优化，即可以在备忘录缓存子串 `"aab"` 的切分结果，避免重复遍历相同的子树。

但用回溯算法就不好加备忘录了，因为回溯算法的 `track` 变量仅维护了从根节点到当前节点走过的路径，并没有记录子树的信息。

所以，这种题目想要消除重叠子问题的话一般要用分解问题的思路，利用函数返回值来更新备忘录。

### [分解问题的思路（动态规划）](#)

这个问题也可以用分解问题的思维解决，把上一道题的 `dp` 函数稍作修改即可：


cpp 🤖

    class Solution {
    public:
        unordered_set<string> wordDict;
        // 备忘录
        vector<vector<string>> memo;
    
        vector<string> wordBreak(string s, vector<string>& wordDict) {
            this->wordDict = unordered_set<string>(wordDict.begin(), wordDict.end());
            this->memo = vector<vector<string>>(s.size());
            return dp(s, 0);
        }
    
        // 定义：返回用 wordDict 构成 s[i..] 的所有可能
        vector<string> dp(string& s, int i) {
            vector<string> res;
            if (i == s.size()) {
                res.push_back("");
                return res;
            }
            // 防止冗余计算
            if (memo[i].size() > 0) {
                return memo[i];
            }
    
            // 遍历 s[i..] 的所有前缀
            for (int len = 1; i + len <= s.size(); len++) {
                // 看看哪些前缀存在 wordDict 中
                string prefix = s.substr(i, len);
                if (wordDict.count(prefix) > 0) {
                    // 找到一个单词匹配 s[i..i+len)
                    vector<string> subProblem = dp(s, i + len);
                    // 构成 s[i+len..] 的所有组合加上 prefix 
                    // 就是构成构成 s[i] 的所有组合
                    for (string sub : subProblem) {
                        if (sub.empty()) {
                            // 防止多余的空格
                            res.push_back(prefix);
                        } else {
                            res.push_back(prefix + " " + sub);
                        }
                    }
                }
            }
            // 存入备忘录
            memo[i] = res;
    
            return res;
        }
    };


这个解法依然用备忘录消除了重叠子问题，所以 `dp` 函数递归调用的次数减少为 O(N)O(N)O(N)，但 `dp` 函数本身的时间复杂度上升了，因为 `subProblem` 是一个子集列表，它的长度是指数级的。

再加上拼接字符串的效率并不高，且还要消耗备忘录去存储所有子问题的结果，所以从 Big O 的角度来分析，这个算法的时间复杂度并不比回溯算法低，依然是指数级别；但这个解法确实消除了重叠子问题，所以是要比回溯算法高明一些。

综上，我们处理排列组合问题时一般使用回溯算法去「遍历」回溯树，而不用「分解问题」的思路去处理，因为存储子问题的结果就需要大量的时间和空间，除非重叠子问题的数量较多的极端情况，否则得不偿失。

以上就是本文的全部内容，希望你能对回溯思路和分解问题的思路有更深刻的理解。



# 遍历方向详解

前置知识

阅读本文前，你需要先学习：

*   [动态规划核心框架](https://labuladong.online/algo/essential-technique/dynamic-programming-framework/)

本文是旧文 [动态规划答疑篇](https://mp.weixin.qq.com/s/qvlfyKBiXVX7CCwWFR-XKg) 的修订版，根据我的不断学习总结以及读者的评论反馈，我给扩展了更多内容，力求使本文成为继 [动态规划核心套路框架](https://labuladong.online/algo/essential-technique/dynamic-programming-framework/) 之后的一篇全面答疑文章。以下是正文。

这篇文章就给你讲明白以下几个问题：

1、到底什么才叫「最优子结构」，和动态规划什么关系。

2、如何判断一个问题是动态规划问题，即如何看出是否存在重叠子问题。

3、为什么经常看到将 `dp` 数组的大小设置为 `n + 1` 而不是 `n`。

4、为什么动态规划遍历 `dp` 数组的方式五花八门，有的正着遍历，有的倒着遍历，有的斜着遍历。

[一、最优子结构详解](#)
--------------

「最优子结构」是某些问题的一种特定性质，并不是动态规划问题专有的。也就是说，很多问题其实都具有最优子结构，只是其中大部分不具有重叠子问题，所以我们不把它们归为动态规划系列问题而已。

我先举个很容易理解的例子：假设你们学校有 10 个班，你已经计算出了每个班的最高考试成绩。那么现在我要求你计算全校最高的成绩，你会不会算？当然会，而且你不用重新遍历全校学生的分数进行比较，而是只要在这 10 个最高成绩中取最大的就是全校的最高成绩。

我给你提出的这个问题就**符合最优子结构**：可以从子问题的最优结果推出更大规模问题的最优结果。让你算**每个班**的最优成绩就是子问题，你知道所有子问题的答案后，就可以借此推出**全校**学生的最优成绩这个规模更大的问题的答案。

你看，这么简单的问题都有最优子结构性质，只是因为显然没有重叠子问题，所以我们简单地求最值肯定用不出动态规划。

再举个例子：假设你们学校有 10 个班，你已知每个班的最大分数差（最高分和最低分的差值）。那么现在我让你计算全校学生中的最大分数差，你会不会算？可以想办法算，但是肯定不能通过已知的这 10 个班的最大分数差推到出来。因为这 10 个班的最大分数差不一定就包含全校学生的最大分数差，比如全校的最大分数差可能是 3 班的最高分和 6 班的最低分之差。

这次我给你提出的问题就**不符合最优子结构**，因为你没办通过每个班的最优值推出全校的最优值，没办法通过子问题的最优值推出规模更大的问题的最优值。前文 [动态规划详解](https://labuladong.online/algo/essential-technique/dynamic-programming-framework/) 说过，想满足最优子结，子问题之间必须互相独立。全校的最大分数差可能出现在两个班之间，显然子问题不独立，所以这个问题本身不符合最优子结构。

**那么遇到这种最优子结构失效情况，怎么办？策略是：改造问题**。对于最大分数差这个问题，我们不是没办法利用已知的每个班的分数差吗，那我只能这样写一段暴力代码：

    int result = 0;
    for (Student a : school) {
        for (Student b : school) {
            if (a is b) continue;
            result = max(result, |a.score - b.score|);
        }
    }
    return result;

改造问题，也就是把问题等价转化：最大分数差，不就等价于最高分数和最低分数的差么，那不就是要求最高和最低分数么，不就是我们讨论的第一个问题么，不就具有最优子结构了么？那现在改变思路，借助最优子结构解决最值问题，再回过头解决最大分数差问题，是不是就高效多了？

当然，上面这个例子太简单了，不过请读者回顾一下，我们做动态规划问题，是不是一直在求各种最值，本质跟我们举的例子没啥区别，无非需要处理一下重叠子问题。

后文 [高楼扔鸡蛋问题](https://labuladong.online/algo/dynamic-programming/egg-drop/) 就展示了如何改造问题，不同的最优子结构，可能导致不同的解法和效率。

再举个常见但也十分简单的例子，求一棵二叉树的最大值，不难吧（简单起见，假设节点中的值都是非负数）：

cpp 🤖

    int maxVal(TreeNode* root) {
        if (root == nullptr)
            return -1;
        int left = maxVal(root->left);
        int right = maxVal(root->right);
        return max(root->val, max(left, right));
    }


你看这个问题也符合最优子结构，以 `root` 为根的树的最大值，可以通过两边子树（子问题）的最大值推导出来，结合刚才学校和班级的例子，很容易理解吧。

当然这也不是动态规划问题，旨在说明，最优子结构并不是动态规划独有的一种性质，能求最值的问题大部分都具有这个性质；**但反过来，最优子结构性质作为动态规划问题的必要条件，一定是让你求最值的**，以后碰到那种恶心人的最值题，思路往动态规划想就对了，这就是套路。

动态规划不就是从最简单的 base case 往后推导吗，可以想象成一个链式反应，以小博大。但只有符合最优子结构的问题，才有发生这种链式反应的性质。

找最优子结构的过程，其实就是证明状态转移方程正确性的过程，方程符合最优子结构就可以写暴力解了，写出暴力解就可以看出有没有重叠子问题了，有则优化，无则 OK。这也是套路，经常刷题的读者应该能体会。

这里就不举那些正宗动态规划的例子了，读者可以翻翻历史文章，看看状态转移是如何遵循最优子结构的，这个话题就聊到这，下面再来看其他的动态规划迷惑行为。

[二、如何一眼看出重叠子问题](#)
------------------

经常有读者说：

看了前文 [动态规划核心套路](https://labuladong.online/algo/essential-technique/dynamic-programming-framework/)，我知道了如何一步步优化动态规划问题；

看了前文 [动态规划设计：数学归纳法](https://labuladong.online/algo/dynamic-programming/longest-increasing-subsequence/)，我知道了利用数学归纳法写出暴力解（状态转移方程）。

**但就算我写出了暴力解，我很难判断这个解法是否存在重叠子问题**，从而无法确定是否可以运用备忘录等方法去优化算法效率。

对于这个问题，其实我在动态规划系列的文章中写过几次，在这里再统一总结一下吧。

**首先，最简单粗暴的方式就是画图，把递归树画出来，看看有没有重复的节点**。

比如最简单的例子，[动态规划核心套路](https://labuladong.online/algo/essential-technique/dynamic-programming-framework/) 中斐波那契数列的递归树：

![](https://labuladong.online/algo/images/dynamic-programming/1.jpg)

这棵递归树很明显存在重复的节点，所以我们可以通过备忘录避免冗余计算。

但毕竟斐波那契数列问题太简单了，实际的动态规划问题比较复杂，比如二维甚至三维的动态规划，当然也可以画递归树，但不免有些复杂。

比如在 [最小路径和问题](https://labuladong.online/algo/dynamic-programming/minimum-path-sum/) 中，我们写出了这样一个暴力解法：


cpp 🤖

    int dp(vector<vector<int>>& grid, int i, int j) {
        if (i == 0 && j == 0) {
            return grid[0][0];
        }
        if (i < 0 || j < 0) {
            return INT_MAX;
        }
    
        return min(
                dp(grid, i - 1, j), 
                dp(grid, i, j - 1)
            ) + grid[i][j];
    }


你不需要读过前文，光看这个函数代码就能看出来，该函数递归过程中参数 `i, j` 在不断变化，即「状态」是 `(i, j)` 的值，你是否可以判断这个解法是否存在重叠子问题呢？

假设输入的 `i = 8, j = 7`，二维状态的递归树如下图，显然出现了重叠子问题：

![](https://labuladong.online/algo/images/optimal/2.jpeg)

**但稍加思考就可以知道，其实根本没必要画图，可以通过递归框架直接判断是否存在重叠子问题**。

具体操作就是直接删掉代码细节，抽象出该解法的递归框架：

    int dp(int[][] grid, int i, int j) {
        dp(grid, i - 1, j), // #1
        dp(grid, i, j - 1)  // #2
    }

可以看到 `i, j` 的值在不断减小，那么我问你一个问题：如果我想从状态 `(i, j)` 转移到 `(i-1, j-1)`，有几种路径？

显然有两种路径，可以是 `(i, j) -> #1 -> #2` 或者 `(i, j) -> #2 -> #1`，不止一种，说明 `(i-1, j-1)` 会被多次计算，所以一定存在重叠子问题。

再举个稍微复杂的例子，后文 [正则表达式问题](https://labuladong.online/algo/dynamic-programming/regular-expression-matching/) 的暴力解代码：

cpp 🤖

    bool dp(string s, int i, string p, int j) {
        int m = s.size(), n = p.size();
        // base case
        if (j == n) {
            return i == m;
        }
        if (i == m) {
            if ((n - j) % 2 == 1) {
                return false;
            }
            for (; j + 1 < n; j += 2) {
                if (p[j + 1] != '*') {
                    return false;
                }
            }
            return true;
        }
    
        bool res = false;
    
        if (s[i] == p[j] || p[j] == '.') {
            if (j < n - 1 && p[j + 1] == '*') {
                res = dp(s, i, p, j + 2) || dp(s, i + 1, p, j);
            } else {
                res = dp(s, i + 1, p, j + 1);
            }
        } else {
            if (j < n - 1 && p[j + 1] == '*') {
                res = dp(s, i, p, j + 2);
            } else {
                res = false;
            }
        }
        
        return res;
    }


代码有些复杂对吧，如果画图的话有些麻烦，但我们不画图，直接忽略所有细节代码和条件分支，只抽象出递归框架：

    boolean dp(String s, int i, String p, int j) {
        dp(s, i, p, j + 2);     // #1
        dp(s, i + 1, p, j);     // #2
        dp(s, i + 1, p, j + 1); // #3
    }

和上一题一样，这个解法的「状态」也是 `(i, j)` 的值，那么我继续问你问题：如果我想从状态 `(i, j)` 转移到 `(i+2, j+2)`，有几种路径？

显然，至少有两条路径：`(i, j) -> #1 -> #2 -> #2` 和 `(i, j) -> #3 -> #3`，这就说明这个解法存在巨量重叠子问题。

所以，不用画图就知道这个解法也存在重叠子问题，需要用备忘录技巧去优化。

[三、dp 数组的大小设置](#)
-----------------

比如说后文 [编辑距离问题](https://labuladong.online/algo/dynamic-programming/edit-distance/)，我首先讲的是自顶向下的递归解法，实现了这样一个 `dp` 函数：

cpp 🤖

    class Solution {
    public:
        int minDistance(string s1, string s2) {
            int m = s1.length(), n = s2.length();
            // 按照 dp 函数的定义，计算 s1 和 s2 的最小编辑距离
            return dp(s1, m - 1, s2, n - 1);
        }
    
        // 定义：s1[0..i] 和 s2[0..j] 的最小编辑距离是 dp(s1, i, s2, j)
        int dp(string s1, int i, string s2, int j) {
            // 处理 base case
            if (i == -1) {
                return j + 1;
            }
            if (j == -1) {
                return i + 1;
            }
    
            // 进行状态转移
            if (s1[i] == s2[j]) {
                return dp(s1, i - 1, s2, j - 1);
            } else {
                return min3(
                    dp(s1, i, s2, j - 1) + 1,
                    dp(s1, i - 1, s2, j) + 1,
                    dp(s1, i - 1, s2, j - 1) + 1
                );
            }
        }
        
    private:
        int min3(int a, int b, int c) {
            return min(a, min(b, c));
        }
    };


然后改造成了自底向上的迭代解法：


cpp 🤖

    class Solution {
    public:
        int minDistance(string s1, string s2) {
            int m = s1.length(), n = s2.length();
            // 定义：s1[0..i] 和 s2[0..j] 的最小编辑距离是 dp[i+1][j+1]
            vector<vector<int>> dp(m + 1, vector<int>(n + 1));
            // 初始化 base case 
            for (int i = 1; i <= m; i++)
                dp[i][0] = i;
            for (int j = 1; j <= n; j++)
                dp[0][j] = j;
    
            // 自底向上求解
            for (int i = 1; i <= m; i++) {
                for (int j = 1; j <= n; j++) {
                    // 进行状态转移
                    if (s1[i-1] == s2[j-1]) {
                        dp[i][j] = dp[i - 1][j - 1];
                    } else {
                        dp[i][j] = min(
                            dp[i - 1][j] + 1,
                            min(dp[i][j - 1] + 1,
                                dp[i - 1][j - 1] + 1)
                        );
                    }
                }
            }
            // 按照 dp 数组的定义，存储 s1 和 s2 的最小编辑距离
            return dp[m][n];
        }
    };


这两种解法思路是完全相同的，但就有读者提问，为什么迭代解法中的 `dp` 数组初始化大小要设置为 `int[m+1][n+1]`？为什么 `s1[0..i]` 和 `s2[0..j]` 的最小编辑距离要存储在 `dp[i+1][j+1]` 中，有一位索引偏移？

能不能模仿 `dp` 函数的定义，把 `dp` 数组初始化为 `int[m][n]`，然后让 `s1[0..i]` 和 `s2[0..j]` 的最小编辑距离要存储在 `dp[i][j]` 中？

**理论上，你怎么定义都可以，只要根据定义处理好 base case 就可以**。

你看 `dp` 函数的定义，`dp(s1, i, s2, j)` 计算 `s1[0..i]` 和 `s2[0..j]` 的编辑距离，那么 `i, j` 等于 -1 时代表空串的 base case，所以函数开头处理了这两种特殊情况。

再看 `dp` 数组，你当然也可以定义 `dp[i][j]` 存储 `s1[0..i]` 和 `s2[0..j]` 的编辑距离，但问题是 base case 怎么搞？索引怎么能是 -1 呢？

所以我们把 `dp` 数组初始化为 `int[m+1][n+1]`，让索引整体偏移一位，把索引 0 留出来作为 base case 表示空串，然后定义 `dp[i+1][j+1]` 存储 `s1[0..i]` 和 `s2[0..j]` 的编辑距离。

[四、dp 数组的遍历方向](#)
-----------------

我相信读者做动态规问题时，肯定会对 `dp` 数组的遍历顺序有些头疼。我们拿二维 `dp` 数组来举例，有时候我们是正向遍历：

    int[][] dp = new int[m][n];
    for (int i = 0; i < m; i++)
        for (int j = 0; j < n; j++)
            // 计算 dp[i][j]

有时候我们反向遍历：

    for (int i = m - 1; i >= 0; i--)
        for (int j = n - 1; j >= 0; j--)
            // 计算 dp[i][j]

有时候可能会斜向遍历：

    // 斜着遍历数组
    for (int l = 2; l <= n; l++) {
        for (int i = 0; i <= n - l; i++) {
            int j = l + i - 1;
            // 计算 dp[i][j]
        }
    }

甚至更让人迷惑的是，有时候发现正向反向遍历都可以得到正确答案，比如我们在 [团灭股票问题](https://labuladong.online/algo/dynamic-programming/stock-problem-summary/) 中有的地方就正反皆可。

如果仔细观察的话可以发现其中的原因，你只要把住两点就行了：

**1、遍历的过程中，所需的状态必须是已经计算出来的**。

**2、遍历结束后，存储结果的那个位置必须已经被计算出来**。

下面来具体解释上面两个原则是什么意思。

比如 [编辑距离](https://labuladong.online/algo/dynamic-programming/edit-distance/) 这个经典的问题，我们通过对 `dp` 数组的定义，确定了 base case 是 `dp[..][0]` 和 `dp[0][..]`，最终答案是 `dp[m][n]`；而且我们通过状态转移方程知道 `dp[i][j]` 需要从 `dp[i-1][j]`, `dp[i][j-1]`, `dp[i-1][j-1]` 转移而来，如下图：

![](https://labuladong.online/algo/images/optimal/1.jpg)

那么，参考刚才说的两条原则，你该怎么遍历 `dp` 数组？肯定是正向遍历：

    for (int i = 1; i < m; i++)
        for (int j = 1; j < n; j++)
            // 通过 dp[i-1][j], dp[i][j - 1], dp[i-1][j-1]
            // 计算 dp[i][j]

因为，这样每一步迭代的左边、上边、左上边的位置都是 base case 或者之前计算过的，而且最终结束在我们想要的答案 `dp[m][n]`。

再举一例，回文子序列问题，详见后文 [子序列问题模板](https://labuladong.online/algo/dynamic-programming/subsequence-problem/)，我们通过过对 `dp` 数组的定义，确定了 base case 处在中间的对角线，`dp[i][j]` 需要从 `dp[i+1][j]`, `dp[i][j-1]`, `dp[i+1][j-1]` 转移而来，想要求的最终答案是 `dp[0][n-1]`，如下图：

![](https://labuladong.online/algo/images/lps/4.jpg)

这种情况根据刚才的两个原则，就可以有两种正确的遍历方式：

![](https://labuladong.online/algo/images/lps/5.jpg)

要么从左上至右下斜着遍历，要么从下向上从左到右遍历，这样才能保证每次 `dp[i][j]` 的左边、下边、左下边已经计算完毕，得到正确结果。

现在，你应该理解了这两个原则，主要就是看 base case 和最终结果的存储位置，保证遍历过程中使用的数据都是计算完毕的就行，有时候确实存在多种方法可以得到正确答案，可根据个人口味自行选择。

* * *

**引用本文的题目**

[115. 不同的子序列](https://leetcode.cn/problems/distinct-subsequences/?show=1) 🔴

[139. 单词拆分](https://leetcode.cn/problems/word-break/?show=1) 

[221. 最大正方形](https://leetcode.cn/problems/maximal-square/?show=1) 

[256. 粉刷房子](https://leetcode.cn/problems/paint-house/?show=1) 🔒

[343. 整数拆分](https://leetcode.cn/problems/integer-break/?show=1) 

[剑指 Offer II 091. 粉刷房子](https://leetcode.cn/problems/JEj789/?show=1) 

[剑指 Offer II 097. 子序列的数目](https://leetcode.cn/problems/21dk04/?show=1) 🔴