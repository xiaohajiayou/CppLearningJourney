
## 知识点覆盖
- c/c++、python
- arm neon指令、汇编优化、GPU优化
- 算子计算原理、推理框架模型解析
- 熟悉常用图像视觉计算库及深度学习推理计算库：arm compute library
- 熟悉常用的卷积计算优化方法：gemm、winograd算法
- 了解编译原理和相关编译优化技术：TVM/MLIR/IREE
- 了解主流AIGC算法模型原理
- 开源推理框架贡献：DeepSpeed，FasterTransformer、vllm、lmdeploy、ncnn、tensorRT
- 你得了解计算图和 OP 的优化，得了解各种推理框架，缓存/显存优化，还有 LLM 结构运行时的系统架构。这个岗位一般不推荐新人入场，因为太吃经验了。建议先从 2 进场，然后逐步转到 4。
- 搜推场景推理服务研发：使用ONNX Runtime/TensorRT等框架，深度优化GPU/CPU模型推理效率，打造高吞吐低延迟的模型推理服务。支持大规模稀疏模型的分布式存储、实时更新、低延迟通信，提供行业先进的推理引擎。探索下一代基于大规模稠密参数的推荐服务。
- 大模型推理优化：使用SGLang/vLLM/TensorRT-LLM/Triton-Inference-Server等框架和引擎，部署和优化包括但不限于蚂蚁内部大模型、千问、DeepSeek等大模型推理的极致性能。以推理系统工程为主 (工程与算法结合)，积极探索业界前沿技术，打造SOTA推理性能。
- 了解分布式推理、量化、稀疏加速，或对算子、访存、通信优化等有一定经验。
## cuda学习资料
![alt text](images/image.png)
- 樊哲勇 cuda书籍
- 知乎bbuf 公众号giantpandacv
- 知乎onflow
- b站 nsight compute

## 入门项目
- 可以试试用cuda实现reduce/histogram/softmax/gemm/scan/sort之类的算法，尤其是gemm，感觉高性能计算方向大概率会问，知乎上也有很多大佬写的文章可以参考，cuda core和tensor core的实现都有。（如果都实现过了，当我没说...   
- 如果是大模型部署和推理优化的话，感觉还需要了解一点fastertransformer、flashattention和vllm之类的框架
- 推理框架优化（内存优化、分层框架）、算子优化（cvpr最新算子支持，插件实现、异构推理）方向     

## 开源贡献

![alt text](images/image-1.png)


## 面经
### cuda
*   cuda graph作用原理，kernel launch流程
*   如何确定blocksize和gridsize
*   什么是default stream，它存在什么问题
*   shared memor的bank conflict及解决方法
*   threadfence的作用
*   如何debug cuda kernel
*   unified memory和zero-copy memory
*   cuda sort如何实现
*   sin函数在哪个硬件计算，这个硬件还能算什么
*   Volat架构特性，ITS
*   3090上单个block能用的shmem最大有多少
*   PTX与SASS的区别
*   GPU性能xx TFLOPS是怎么计算的
*   
### cpp
*   C++虚函数实现机制，单继承、多继承、虚继承的内存布局
*   四种cast
*   三种智能指针
*   函数模板声明与定义能否分离
*   CRTP静态多态
*   vector扩容，resize和reserve
*   单例模式
*   

### 手撕
做推理优化和高性能计算肯定是要懂点cuda，所以大部分的题目都是用cuda实现，一些不太好用cuda实现的如NMS就用c++写了。当然也遇到过一些力扣题目，基本是hot100的范畴，这里不再赘述。

cuda实现：reduction，softmax，matrix transpose，avg pooling，算两堆bbox的iou，大部分情况下都是实现kernel即可，少数情况需要跟cpu对齐。

c++实现：NMS，conv2d，双线性插值，layernorm，单例模式

这里面让我印象比较深刻的是layernorm，用cuda写个layernorm不难，但面试官让我用vadd/vsub/vmul/vdiv等向量指令实现一个layernorm，我人都傻了。一是咱平时写cuda都是SIMT的编程模型，cpu优化是SIMD，这俩写起来有差别；二是没提供sqrt，得自己用牛顿法求，而且还没有比较运算符，浮点数的比较还有一些trick，最后肯定是寄了。

另外就是某大模型公司，要求实现softmax，需要跟cpu版本对齐。

