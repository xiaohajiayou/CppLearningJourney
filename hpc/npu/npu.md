![alt text](image.png)
![alt text](image-2.png)
![alt text](image-1.png)
硬件排列格式
nc1whc0

nchw -》 bm1
![alt text](image-3.png)
![alt text](image-4.png)
![alt text](image-5.png)
中间结果支持硬件cast函数（子数normalize）
![alt text](image-6.png)

fp16
fp16 + 量化

## 模拟器调试
cpu配合算子调试比对

## llm
### 动态与静态
动态moe

## cv
工具链编译，扔给驱动直接出结果，不需要运行时接口


## 高性能
llama.cpp传整图，编译后走完整runtime

## 具体算子实现
### matmul
输出+reshape+transpose
llama.cpp差异（对比pytorch）
### reshape
逻辑偏移，后序是否连续

### sofxmax
llama.cpp里实现，softmax掩码实现在了softmax里



## 量化
### 对称量化
有符号数

### 非对称量化
无符号数



## 存储形态
bm1n1m0n0性能最好，功耗最低
你提到的这些数据排布（如NCHW、NHWC、NC1HWC0、BMN、bmn1n1m0n0）本质上是**多维张量在内存中的存储顺序规则**，用于规范不同维度的数据如何映射到连续的内存地址中。它们的设计通常与硬件架构（如GPU、专用AI芯片）的计算效率密切相关，不仅限于CV领域，在LLM等其他AI场景中也可能因计算需求或硬件约束而存在类似的多维维度划分。


### 一、常见数据排布的含义与适用场景
#### 1. **NCHW 与 NHWC（最基础的CV领域排布）**
   - **维度含义**（以图像数据为例）：
     - **N**：Batch Size（批次大小，即样本数量）；
     - **C**：Channels（通道数，如RGB图像的3个通道）；
     - **H**：Height（图像高度，行数）；
     - **W**：Width（图像宽度，列数）。
   - **存储顺序差异**：
     - **NCHW**：按“批次→通道→高度→宽度”的顺序存储，同一通道的所有像素连续排列（适合NVIDIA GPU等架构，利用其缓存特性）；
     - **NHWC**：按“批次→高度→宽度→通道”的顺序存储，同一空间位置的多通道像素连续排列（适合CPU、移动端GPU等，优化内存访问效率）。
   - **为何LLM中可能出现？**  
     即使LLM处理的是文本，其输入（如词嵌入序列）也可能被视为“伪图像”类的多维数据。例如：
     - 文本序列可视为“1通道的1D图像”：N（批次）、C（特征维度，类似通道）、H（序列长度，类似高度）、W（1，因文本是1D）；
     - 部分LLM的中间特征可能被硬件优化层强制按NCHW/NHWC格式存储（如专用AI芯片要求统一数据格式）。


#### 2. **NC1HWC0（华为昇腾芯片常用的5D排布）**
   - **维度含义**（针对高维特征优化）：
     - **N**：Batch Size；
     - **C1**：通道的第一级拆分（通常与硬件核心数匹配）；
     - **H**：高度；
     - **W**：宽度；
     - **C0**：通道的第二级拆分（通常与硬件向量计算单元宽度匹配，如16、32）。
   - **设计目的**：  
     通过将通道（C）拆分为C1和C0，使数据更贴合昇腾芯片的“多核心+向量计算单元”架构，提升并行计算效率。
   - **LLM中的可能应用**：  
     若LLM在昇腾芯片上部署，其隐藏层特征（形状为[N, SeqLen, Dim]）可能被转换为类似格式（如N→批次，C1→特征维度拆分，H→序列长度，W→1，C0→向量单元宽度），以适配硬件计算逻辑。


#### 3. **BMN（通用多维拆分排布）**
   - **维度含义**（通常表示三级拆分）：
     - **B**：Batch的拆分维度（如按硬件核心数拆分批次）；
     - **M**：特征维度的拆分（如模型隐藏层维度的拆分）；
     - **N**：序列或其他维度的拆分（如LLM中的序列长度拆分）。
   - **设计目的**：  
     针对多维度并行计算（如数据并行、模型并行），将大张量拆分为小份分配到不同计算单元，适合分布式场景。
   - **LLM中的核心作用**：  
     LLM的输入序列长、模型参数大，需通过BMN等拆分方式实现并行计算（如B拆分批次、M拆分隐藏层、N拆分序列），提升计算效率。


#### 4. **bmn1n1m0n0（硬件特定的精细排布）**
   - 这类带数字的标识符更可能是**硬件厂商自定义的精细化维度拆分规则**（如地平线、比特大陆等AI芯片），其中：
     - 小写字母（b、m、n）可能对应基础维度（如batch、model、sequence）；
     - 数字（1、0）可能表示拆分开关（1=启用拆分，0=不拆分）或拆分粒度（如1表示按1:1拆分）。
   - 例如：`b1m0n1` 可能表示“batch维度拆分（1级）、model维度不拆分、sequence维度拆分（1级）”，用于适配特定硬件的并行计算单元。



## 开发形态
### docker

### fpga


## 编译要求
-  llama.cpp要求gcc 13以上
-  

## 生图框架
## comfy ui
### stable diffusion.cpp
每次forward 都需要重新build，图动态转静态
